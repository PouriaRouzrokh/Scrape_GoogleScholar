{
  "author": "Pouria Rouzrokh",
  "affiliation": "Assistant Professor, Department of Radiology, Mayo Clinic, MN, USA",
  "google_scholar_id": "Ksv9I0sAAAAJ",
  "metrics": {
    "citations": 1344,
    "h_index": 21,
    "i10_index": 37,
    "cited_by_5_years": 1335
  },
  "total_articles": 75,
  "total_citations": 1344,
  "total_articles_processed": 73,
  "total_citations_processed": 1341,
  "fetched_at": "2025-05-16 13:30:13 UTC",
  "articles": [
    {
      "title": "TKA-AID: An uncertainty-aware deep learning classifier to identify total knee arthroplasty implants",
      "authors": "Kellen L Mulford, Sami Saniei, Elizabeth S Kaji, Austin F Grove, Miguel Girod-Hoffman, Pouria Rouzrokh, Matthew P Abdel, Michael J Taunton, Cody C Wyles",
      "year": 2025,
      "journal": "The Journal of Arthroplasty",
      "volume": "",
      "number": "",
      "pages": "",
      "publisher": "Churchill Livingstone",
      "abstract": "Background\nA drastic increase in the volume of primary total knee arthroplasties (TKAs) performed nationwide will inevitably lead to higher volumes of revision TKAs in which the primary knee implant must be removed. An important step in preoperative planning for revision TKA is implant identification, which is time-consuming and difficult even for experienced surgeons. We sought to develop a deep learning algorithm to automatically identify the most common models of primary TKA implants.\nMethods\nWe used an institutional total joint registry to pull images and implant data for 9,651 patients (N = 111,519 images). We trained a deep learning model based on the EfficientNet architecture to identify nine different TKA systems across all common knee radiographic views. Model performance was assessed on internal held-out test set and external test set. Conformal prediction was employed to provide uncertainty \u2026",
      "num_citations": 1,
      "url": "https://www.sciencedirect.com/science/article/pii/S0883540325000348",
      "article_id": "tka-aid-an-uncertainty-aware-deep-learning",
      "bibtex": "@article{mulford2025tka,\n  author = {Kellen L Mulford and Sami Saniei and Elizabeth S Kaji and Austin F Grove and Miguel Girod-Hoffman and Pouria Rouzrokh and Matthew P Abdel and Michael J Taunton and Cody C Wyles},\n  title = {TKA-AID: An uncertainty-aware deep learning classifier to identify total knee arthroplasty implants},\n  journal = {The Journal of Arthroplasty},\n  year = {2025},\n  publisher = {Churchill Livingstone},\n  url = {https://www.sciencedirect.com/science/article/pii/S0883540325000348}\n}"
    },
    {
      "title": "Uncertainty-aware deep learning characterization of knee radiographs for large-scale registry creation",
      "authors": "Kellen L Mulford, Austin F Grove, Elizabeth S Kaji, Pouria Rouzrokh, Ryan D Roman, Mete Kremers, Hilal Maradit Kremers, Michael J Taunton, Cody C Wyles",
      "year": 2025,
      "journal": "The Journal of Arthroplasty",
      "volume": "40",
      "number": "5",
      "pages": "1232-1238",
      "publisher": "Churchill Livingstone",
      "abstract": "Background\nWe present an automated image ingestion pipeline for a knee radiography registry, integrating a multilabel image-semantic classifier with conformal prediction-based uncertainty quantification and an object detection model for knee hardware.\nMethods\nAnnotators retrospectively classified 26,000 knee images detailing presence, laterality, prostheses, and radiographic views. They further annotated surgical construct locations in 11,841 knee radiographs. An uncertainty-aware multilabel EfficientNet-based classifier was trained to identify the knee laterality, implants, and radiographic view. A classifier trained with embeddings from the EfficientNet model detected out-of-domain images. An object detection model was trained to identify 20 different knee implants. Model performance was assessed against a held-out internal and an external dataset using per-class F1 score, accuracy, sensitivity, and specificity \u2026",
      "num_citations": 2,
      "url": "https://www.sciencedirect.com/science/article/pii/S0883540324011434",
      "article_id": "uncertainty-aware-deep-learning-characteriz",
      "bibtex": "@article{mulford2025uncertainty,\n  author = {Kellen L Mulford and Austin F Grove and Elizabeth S Kaji and Pouria Rouzrokh and Ryan D Roman and Mete Kremers and Hilal Maradit Kremers and Michael J Taunton and Cody C Wyles},\n  title = {Uncertainty-aware deep learning characterization of knee radiographs for large-scale registry creation},\n  journal = {The Journal of Arthroplasty},\n  volume = {40},\n  number = {5},\n  pages = {1232-1238},\n  year = {2025},\n  publisher = {Churchill Livingstone},\n  url = {https://www.sciencedirect.com/science/article/pii/S0883540324011434}\n}"
    },
    {
      "title": "A Current Review of Generative AI in Medicine: Core Concepts, Applications, and Current Limitations",
      "authors": "Pouria Rouzrokh, Bardia Khosravi, Shahriar Faghani, Mana Moassefi, M Moein Shariatnia, Parsa Rouzrokh, Bradley Erickson",
      "year": 2025,
      "journal": "Current Reviews in Musculoskeletal Medicine",
      "volume": "",
      "number": "",
      "pages": "1-21",
      "publisher": "Springer US",
      "abstract": "Generative AI holds significant transformative potential in medicine, enhancing capabilities across imaging, documentation, education, and decision support. However, its integration faces substantial challenges, including models\u2019 knowledge limitations, the risk of generating incorrect or uncertain \u201challucinated\u201d outputs, inherent biases from training data, difficulty in interpreting model reasoning (\u201cblack box\u201d nature), and navigating complex regulatory and ethical issues. This review offers a balanced perspective, acknowledging both the promise and the hurdles. While Generative AI is unlikely to fully replace physicians, understanding and leveraging these technologies will be crucial for medical professionals navigating the evolving healthcare landscape.",
      "num_citations": 1,
      "url": "https://link.springer.com/article/10.1007/s12178-025-09961-y",
      "article_id": "a-current-review-of-generative-ai-in-medicine",
      "bibtex": "@article{rouzrokh2025current,\n  author = {Pouria Rouzrokh and Bardia Khosravi and Shahriar Faghani and Mana Moassefi and M Moein Shariatnia and Parsa Rouzrokh and Bradley Erickson},\n  title = {A Current Review of Generative AI in Medicine: Core Concepts, Applications, and Current Limitations},\n  journal = {Current Reviews in Musculoskeletal Medicine},\n  pages = {1-21},\n  year = {2025},\n  publisher = {Springer US},\n  url = {https://link.springer.com/article/10.1007/s12178-025-09961-y}\n}"
    },
    {
      "title": "Bone Appetit: Skellytour Sets the Table for Robust Skeletal Segmentation",
      "authors": "Bardia Khosravi, Pouria Rouzrokh",
      "year": 2025,
      "journal": "Radiology: Artificial Intelligence",
      "volume": "7",
      "number": "2",
      "pages": "e250057",
      "abstract": "No abstract available",
      "num_citations": 0,
      "url": "https://pubs.rsna.org/doi/full/10.1148/ryai.250057",
      "article_id": "bone-appetit-skellytour-sets-the-table-f-4c167fe6",
      "bibtex": "@article{rouzrokh2025bone,\n    author = {Bardia Khosravi and Pouria Rouzrokh},\n    title = {Bone Appetit: Skellytour Sets the Table for Robust Skeletal Segmentation},\n    year = {2025},\n    journal = {Radiology: Artificial Intelligence},\n    volume = {7},\n    number = {2},\n    pages = {e250057},\n    note = {bone-appetit-skellytour-sets-the-table-f-4c167fe6},\n    url = {https://pubs.rsna.org/doi/full/10.1148/ryai.250057},\n    abstract = {Bardia Khosravi, MD, MPH, MHPE, is an incoming radiology resident at the Yale University department of radiology and a member of the trainee editorial board of Radiology: Artificial Intelligence. He has held research positions at Mayo Clinic and Emory University, focusing on generative artificial intelligence (AI) models in medical imaging and human-AI interaction. His work on synthetic data generation and AI education has been recognized with awards from the Society for Imaging Informatics in Medicine and the Radiological Society of North America (RSNA).},\n}"
    },
    {
      "title": "Teaching Radiology: An Evidence-based Overview for Radiology Residents",
      "authors": "Helena Bentley, Pouria Rouzrokh, Farhad Pishgar, Jamie E Clarke, Irene Dixe de Oliveira Santo",
      "year": 2025,
      "volume": "45",
      "number": "2",
      "pages": "e240181",
      "abstract": "No abstract available",
      "num_citations": 0,
      "url": "https://pubs.rsna.org/doi/full/10.1148/rg.240181",
      "article_id": "teaching-radiology-an-evidence-based-ove-c1406479",
      "bibtex": "@article{santo2025teaching,\n    author = {Helena Bentley and Pouria Rouzrokh and Farhad Pishgar and Jamie E Clarke and Irene Dixe de Oliveira Santo},\n    title = {Teaching Radiology: An Evidence-based Overview for Radiology Residents},\n    year = {2025},\n    volume = {45},\n    number = {2},\n    pages = {e240181},\n    note = {teaching-radiology-an-evidence-based-ove-c1406479},\n    url = {https://pubs.rsna.org/doi/full/10.1148/rg.240181},\n    abstract = {Volume 45 Number 2 2 radiographics. rsna. org during each teaching encounter. Feedback should also foster a dialogue that encourages learners to ask questions and seek clarification on the feedback that they have received. Feedback should be provided to learners on a continuous basis that regularly determines their progress and facilitates their long-term development of competencies.},\n}"
    },
    {
      "title": "LatteReview: A Multi-Agent Framework for Systematic Review Automation Using Large Language Models",
      "authors": "Pouria Rouzrokh, Moein Shariatnia",
      "year": 2025,
      "abstract": "Systematic literature reviews and meta-analyses are essential for synthesizing research insights, but they remain time-intensive and labor-intensive due to the iterative processes of screening, evaluation, and data extraction. This paper introduces and evaluates LatteReview, a Python-based framework that leverages large language models (LLMs) and multi-agent systems to automate key elements of the systematic review process. Designed to streamline workflows while maintaining rigor, LatteReview utilizes modular agents for tasks such as title and abstract screening, relevance scoring, and structured data extraction. These agents operate within orchestrated workflows, supporting sequential and parallel review rounds, dynamic decision-making, and iterative refinement based on user feedback. LatteReview's architecture integrates LLM providers, enabling compatibility with both cloud-based and locally hosted models. The framework supports features such as Retrieval-Augmented Generation (RAG) for incorporating external context, multimodal reviews, Pydantic-based validation for structured inputs and outputs, and asynchronous programming for handling large-scale datasets. The framework is available on the GitHub repository, with detailed documentation and an installable package.",
      "num_citations": 1,
      "url": "https://arxiv.org/abs/2501.05468",
      "article_id": "lattereview-a-multi-agent-framework-for--41d9d912",
      "bibtex": "@article{shariatnia2025lattereview,\n    author = {Pouria Rouzrokh and Moein Shariatnia},\n    title = {LatteReview: A Multi-Agent Framework for Systematic Review Automation Using Large Language Models},\n    year = {2025},\n    note = {lattereview-a-multi-agent-framework-for--41d9d912},\n    url = {https://arxiv.org/abs/2501.05468},\n    abstract = {Systematic literature reviews and meta-analyses are essential for synthesizing research insights, but they remain time-intensive and labor-intensive due to the iterative processes of screening, evaluation, and data extraction. This paper introduces and evaluates LatteReview, a Python-based framework that leverages large language models (LLMs) and multi-agent systems to automate key elements of the systematic review process. Designed to streamline workflows while maintaining rigor, LatteReview utilizes modular agents for tasks such as title and abstract screening, relevance scoring, and structured data extraction. These agents operate within orchestrated workflows, supporting sequential and parallel review rounds, dynamic decision-making, and iterative refinement based on user feedback. LatteReview's architecture integrates LLM providers, enabling compatibility with both cloud-based and locally hosted models. The framework supports features such as Retrieval-Augmented Generation (RAG) for incorporating external context, multimodal reviews, Pydantic-based validation for structured inputs and outputs, and asynchronous programming for handling large-scale datasets. The framework is available on the GitHub repository, with detailed documentation and an installable package.},\n}"
    },
    {
      "title": "TKA-AID: An Uncertainty-Aware Deep Learning Classifier to Identify Total Knee Arthroplasty Implants",
      "authors": "Kellen L Mulford, Sami Saniei, Elizabeth S Kaji, Austin F Grove, Miguel Girod-Hoffman, Pouria Rouzrokh, Matthew P Abdel, Michael J Taunton, Cody C Wyles",
      "year": 2025,
      "journal": "Journal of Arthroplasty",
      "abstract": "BackgroundA drastic increase in the volume of primary total knee arthroplasties (TKAs) performed nationwide will inevitably lead to higher volumes of revision TKAs in which the primary knee implant must be removed. An important step in preoperative planning for revision TKA is implant identification, which is time-consuming and difficult even for experienced surgeons. We sought to develop a deep learning algorithm to automatically identify the most common models of primary TKA implants.MethodsWe used an institutional total joint registry to pull images and implant data for 9,651 patients (N 111,519 images). We trained a deep learning model based on the EfficientNet architecture to identify nine different TKA systems across all common knee radiographic views. Model performance was assessed on internal held-out test set and external test set. Conformal prediction was employed to provide uncertainty",
      "num_citations": 2,
      "url": "https://www.sciencedirect.com/science/article/pii/S0883540325000348",
      "article_id": "tka-aid-an-uncertainty-aware-deep-learni-f1cdaf1c",
      "bibtex": "@article{wyles2025tkaaid,\n    author = {Kellen L Mulford and Sami Saniei and Elizabeth S Kaji and Austin F Grove and Miguel Girod-Hoffman and Pouria Rouzrokh and Matthew P Abdel and Michael J Taunton and Cody C Wyles},\n    title = {TKA-AID: An Uncertainty-Aware Deep Learning Classifier to Identify Total Knee Arthroplasty Implants},\n    year = {2025},\n    journal = {Journal of Arthroplasty},\n    note = {tka-aid-an-uncertainty-aware-deep-learni-f1cdaf1c},\n    url = {https://www.sciencedirect.com/science/article/pii/S0883540325000348},\n    abstract = {BackgroundA drastic increase in the volume of primary total knee arthroplasties (TKAs) performed nationwide will inevitably lead to higher volumes of revision TKAs in which the primary knee implant must be removed. An important step in preoperative planning for revision TKA is implant identification, which is time-consuming and difficult even for experienced surgeons. We sought to develop a deep learning algorithm to automatically identify the most common models of primary TKA implants.MethodsWe used an institutional total joint registry to pull images and implant data for 9,651 patients (N 111,519 images). We trained a deep learning model based on the EfficientNet architecture to identify nine different TKA systems across all common knee radiographic views. Model performance was assessed on internal held-out test set and external test set. Conformal prediction was employed to provide uncertainty},\n}"
    },
    {
      "title": "Fully automated deep learning model to detect clinically significant prostate cancer at MRI",
      "authors": "Jason C Cai, Hirotsugu Nakai, Shiba Kuanar, Adam T Froemming, Candice W Bolan, Akira Kawashima, Hiroaki Takahashi, Lance A Mynderse, Chandler D Dora, Mitchell R Humphreys, Panagiotis Korfiatis, Pouria Rouzrokh, Alexander K Bratt, Gian Marco Conte, Bradley J Erickson, Naoki Takahashi",
      "year": 2024,
      "journal": "Radiology",
      "volume": "312",
      "number": "2",
      "pages": "e232635",
      "abstract": "Multiparametric MRI can help identify clinically significant prostate cancer (csPCa) (Gleason score 7) but is limited by reader experience and interobserver variability. In contrast, deep learning (DL) produces deterministic outputs.To develop a DL model to predict the presence of csPCa by using patient-level labels without information about tumor location and to compare its performance with that of radiologists.Data from patients without known csPCa who underwent MRI from January 2017 to December 2019 at one of multiple sites of a single academic institution were retrospectively reviewed. A convolutional neural",
      "num_citations": 31,
      "url": "https://pubs.rsna.org/doi/abs/10.1148/radiol.232635",
      "article_id": "fully-automated-deep-learning-model-to-d-d756a99a",
      "bibtex": "@article{takahashi2024fully,\n    author = {Jason C Cai and Hirotsugu Nakai and Shiba Kuanar and Adam T Froemming and Candice W Bolan and Akira Kawashima and Hiroaki Takahashi and Lance A Mynderse and Chandler D Dora and Mitchell R Humphreys and Panagiotis Korfiatis and Pouria Rouzrokh and Alexander K Bratt and Gian Marco Conte and Bradley J Erickson and Naoki Takahashi},\n    title = {Fully automated deep learning model to detect clinically significant prostate cancer at MRI},\n    year = {2024},\n    journal = {Radiology},\n    volume = {312},\n    number = {2},\n    pages = {e232635},\n    note = {fully-automated-deep-learning-model-to-d-d756a99a},\n    url = {https://pubs.rsna.org/doi/abs/10.1148/radiol.232635},\n    abstract = {Multiparametric MRI can help identify clinically significant prostate cancer (csPCa) (Gleason score 7) but is limited by reader experience and interobserver variability. In contrast, deep learning (DL) produces deterministic outputs.To develop a DL model to predict the presence of csPCa by using patient-level labels without information about tumor location and to compare its performance with that of radiologists.Data from patients without known csPCa who underwent MRI from January 2017 to December 2019 at one of multiple sites of a single academic institution were retrospectively reviewed. A convolutional neural},\n}"
    },
    {
      "title": "THA-AID: deep learning tool for total hip arthroplasty automatic implant detection with uncertainty and outlier quantification",
      "authors": "Pouria Rouzrokh, John P Mickley, Bardia Khosravi, Shahriar Faghani, Mana Moassefi, William R Schulz, Bradley J Erickson, Michael J Taunton, Cody C Wyles",
      "year": 2024,
      "journal": "The Journal of Arthroplasty",
      "volume": "39",
      "number": "4",
      "pages": "966-973. e17",
      "abstract": "Revision total hip arthroplasty (THA) requires preoperatively identifying in situ implants, a time-consuming and sometimes unachievable task. Although deep learning (DL) tools have been attempted to automate this process, existing approaches are limited by classifying few femoral and zero acetabular components, only classify on anterior-posterior (AP) radiographs, and do not report prediction uncertainty or flag outlier data.This study introduces Total Hip Arhtroplasty Automated Implant Detector (THA-AID), a DL tool trained on 241,419 radiographs that identifies common designs of 20 femoral and 8 acetabular components from AP, lateral, or oblique views and reports prediction uncertainty using conformal prediction and outlier detection using a custom framework. We evaluated THA-AID using internal, external, and out-of-domain test sets and compared its performance with human experts",
      "num_citations": 19,
      "url": "https://www.sciencedirect.com/science/article/pii/S088354032300983X",
      "article_id": "tha-aid-deep-learning-tool-for-total-hip-e5eae593",
      "bibtex": "@article{wyles2024thaaid,\n    author = {Pouria Rouzrokh and John P Mickley and Bardia Khosravi and Shahriar Faghani and Mana Moassefi and William R Schulz and Bradley J Erickson and Michael J Taunton and Cody C Wyles},\n    title = {THA-AID: deep learning tool for total hip arthroplasty automatic implant detection with uncertainty and outlier quantification},\n    year = {2024},\n    journal = {The Journal of Arthroplasty},\n    volume = {39},\n    number = {4},\n    pages = {966-973. e17},\n    note = {tha-aid-deep-learning-tool-for-total-hip-e5eae593},\n    url = {https://www.sciencedirect.com/science/article/pii/S088354032300983X},\n    abstract = {Revision total hip arthroplasty (THA) requires preoperatively identifying in situ implants, a time-consuming and sometimes unachievable task. Although deep learning (DL) tools have been attempted to automate this process, existing approaches are limited by classifying few femoral and zero acetabular components, only classify on anterior-posterior (AP) radiographs, and do not report prediction uncertainty or flag outlier data.This study introduces Total Hip Arhtroplasty Automated Implant Detector (THA-AID), a DL tool trained on 241,419 radiographs that identifies common designs of 20 femoral and 8 acetabular components from AP, lateral, or oblique views and reports prediction uncertainty using conformal prediction and outlier detection using a custom framework. We evaluated THA-AID using internal, external, and out-of-domain test sets and compared its performance with human experts},\n}"
    },
    {
      "title": "Synthetically enhanced: unveiling synthetic data's potential in medical imaging research",
      "authors": "Bardia Khosravi, Frank Li, Theo Dapamede, Pouria Rouzrokh, Cooper U Gamble, Hari M Trivedi, Cody C Wyles, Andrew B Sellergren, Saptarshi Purkayastha, Bradley J Erickson, Judy W Gichoya",
      "year": 2024,
      "journal": "EBioMedicine",
      "volume": "104",
      "abstract": "Chest X-rays (CXR) are essential for diagnosing a variety of conditions, but when used on new populations, model generalizability issues limit their efficacy. Generative AI, particularly denoising diffusion probabilistic models (DDPMs), offers a promising approach to generating synthetic images, enhancing dataset diversity. This study investigates the impact of synthetic data supplementation on the performance and generalizability of medical imaging research.The study employed DDPMs to create synthetic CXRs conditioned on demographic and pathological characteristics from the CheXpert dataset. These synthetic images were used to supplement training datasets for pathology classifiers, with the aim of improving their performance. The evaluation involved three datasets (CheXpert, MIMIC-CXR, and Emory Chest X-ray) and various experiments, including supplementing real data with",
      "num_citations": 20,
      "url": "https://www.thelancet.com/journals/ebiom/article/PIIS2352-3964(24)00209-3/fulltext?uuid=uuid%3A236a8aec-bcf0-4623-8a53-ff55a7d02a73",
      "article_id": "synthetically-enhanced-unveiling-synthet-118b8ccd",
      "bibtex": "@article{gichoya2024synthetically,\n    author = {Bardia Khosravi and Frank Li and Theo Dapamede and Pouria Rouzrokh and Cooper U Gamble and Hari M Trivedi and Cody C Wyles and Andrew B Sellergren and Saptarshi Purkayastha and Bradley J Erickson and Judy W Gichoya},\n    title = {Synthetically enhanced: unveiling synthetic data's potential in medical imaging research},\n    year = {2024},\n    journal = {EBioMedicine},\n    volume = {104},\n    note = {synthetically-enhanced-unveiling-synthet-118b8ccd},\n    url = {https://www.thelancet.com/journals/ebiom/article/PIIS2352-3964(24)00209-3/fulltext?uuid=uuid\\%3A236a8aec-bcf0-4623-8a53-ff55a7d02a73},\n    abstract = {Chest X-rays (CXR) are essential for diagnosing a variety of conditions, but when used on new populations, model generalizability issues limit their efficacy. Generative AI, particularly denoising diffusion probabilistic models (DDPMs), offers a promising approach to generating synthetic images, enhancing dataset diversity. This study investigates the impact of synthetic data supplementation on the performance and generalizability of medical imaging research.The study employed DDPMs to create synthetic CXRs conditioned on demographic and pathological characteristics from the CheXpert dataset. These synthetic images were used to supplement training datasets for pathology classifiers, with the aim of improving their performance. The evaluation involved three datasets (CheXpert, MIMIC-CXR, and Emory Chest X-ray) and various experiments, including supplementing real data with},\n}"
    },
    {
      "title": "Explaining explainability: The role of XAI in medical imaging",
      "authors": "Jo\u00e3o Abrantes, Pouria Rouzrokh",
      "year": 2024,
      "journal": "European Journal of Radiology",
      "volume": "173",
      "abstract": "Artificial Intelligence (AI) has shown the potential to profoundly impact medical image analysis, encompassing tasks such as detection, classification, diagnosis, segmentation, prediction, and image quality enhancement. Machine Learning (ML) is a set of methods that computers use to make and improve predictions or behaviors based on data. The majority of newly developed models for medical image analysis make use of deep learning (DL), a specific subfield of ML that employs artificial neural networks. This approach allows for the direct processing of raw data by performing all the necessary steps involved in designing a classic ML model, including feature extraction and learning. As ML is progressively applied through deploying more complex models or complicated pipelines, such as using a very large number (anensemble) of simpler models working together tovoteon a prediction or employing deep",
      "num_citations": 12,
      "url": "https://www.ejradiology.com/article/S0720-048X(24)00105-0/abstract",
      "article_id": "explaining-explainability-the-role-of-xa-732f8c74",
      "bibtex": "@article{rouzrokh2024explaining,\n    author = {Jo\u00e3o Abrantes and Pouria Rouzrokh},\n    title = {Explaining explainability: The role of XAI in medical imaging},\n    year = {2024},\n    journal = {European Journal of Radiology},\n    volume = {173},\n    note = {explaining-explainability-the-role-of-xa-732f8c74},\n    url = {https://www.ejradiology.com/article/S0720-048X(24)00105-0/abstract},\n    abstract = {Artificial Intelligence (AI) has shown the potential to profoundly impact medical image analysis, encompassing tasks such as detection, classification, diagnosis, segmentation, prediction, and image quality enhancement. Machine Learning (ML) is a set of methods that computers use to make and improve predictions or behaviors based on data. The majority of newly developed models for medical image analysis make use of deep learning (DL), a specific subfield of ML that employs artificial neural networks. This approach allows for the direct processing of raw data by performing all the necessary steps involved in designing a classic ML model, including feature extraction and learning. As ML is progressively applied through deploying more complex models or complicated pipelines, such as using a very large number (anensemble) of simpler models working together tovoteon a prediction or employing deep},\n}"
    },
    {
      "title": "THA-net: a deep learning solution for next-generation templating and patient-specific surgical execution",
      "authors": "Pouria Rouzrokh, Bardia Khosravi, John P Mickley, Bradley J Erickson, Michael J Taunton, Cody C Wyles",
      "year": 2024,
      "journal": "The Journal of Arthroplasty",
      "volume": "39",
      "number": "3",
      "pages": "727-733. e4",
      "abstract": "This study introduces THA-Net, a deep learning inpainting algorithm for simulating postoperative total hip arthroplasty (THA) radiographs from a single preoperative pelvis radiograph input, while being able to generate predictions either unconditionally (algorithm chooses implants) or conditionally (surgeon chooses implants).The THA-Net is a deep learning algorithm which receives an input preoperative radiograph and subsequently replaces the target hip joint with THA implants to generate a synthetic yet realistic postoperative radiograph. We trained THA-Net on 356,305 pairs of radiographs from 14,357 patients from a single institutions total joint registry and evaluated the validity (quality of surgical execution) and realism (ability to differentiate real and synthetic radiographs) of its outputs against both human-based and software-based criteria.The surgical validity of synthetic",
      "num_citations": 10,
      "url": "https://www.sciencedirect.com/science/article/pii/S0883540323008720",
      "article_id": "tha-net-a-deep-learning-solution-for-nex-4021992e",
      "bibtex": "@article{wyles2024thanet,\n    author = {Pouria Rouzrokh and Bardia Khosravi and John P Mickley and Bradley J Erickson and Michael J Taunton and Cody C Wyles},\n    title = {THA-net: a deep learning solution for next-generation templating and patient-specific surgical execution},\n    year = {2024},\n    journal = {The Journal of Arthroplasty},\n    volume = {39},\n    number = {3},\n    pages = {727-733. e4},\n    note = {tha-net-a-deep-learning-solution-for-nex-4021992e},\n    url = {https://www.sciencedirect.com/science/article/pii/S0883540323008720},\n    abstract = {This study introduces THA-Net, a deep learning inpainting algorithm for simulating postoperative total hip arthroplasty (THA) radiographs from a single preoperative pelvis radiograph input, while being able to generate predictions either unconditionally (algorithm chooses implants) or conditionally (surgeon chooses implants).The THA-Net is a deep learning algorithm which receives an input preoperative radiograph and subsequently replaces the target hip joint with THA implants to generate a synthetic yet realistic postoperative radiograph. We trained THA-Net on 356,305 pairs of radiographs from 14,357 patients from a single institutions total joint registry and evaluated the validity (quality of surgical execution) and realism (ability to differentiate real and synthetic radiographs) of its outputs against both human-based and software-based criteria.The surgical validity of synthetic},\n}"
    },
    {
      "title": "Checklist for reproducibility of deep learning in medical imaging",
      "authors": "Mana Moassefi, Yashbir Singh, Gian Marco Conte, Bardia Khosravi, Pouria Rouzrokh, Sanaz Vahdati, Nabile Safdar, Linda Moy, Felipe Kitamura, Amilcare Gentili, Paras Lakhani, Nina Kottler, Safwan S Halabi, Joseph H Yacoub, Yuankai Hou, Khaled Younis, Bradley J Erickson, Elizabeth Krupinski, Shahriar Faghani",
      "year": 2024,
      "volume": "37",
      "number": "4",
      "pages": "1664-1673",
      "abstract": "The application of deep learning (DL) in medicine introduces transformative tools with the potential to enhance prognosis, diagnosis, and treatment planning. However, ensuring transparent documentation is essential for researchers to enhance reproducibility and refine techniques. Our study addresses the unique challenges presented by DL in medical imaging by developing a comprehensive checklist using the Delphi method to enhance reproducibility and reliability in this dynamic field. We compiled a preliminary checklist based on a comprehensive review of existing checklists and relevant literature. A panel of 11 experts in medical imaging and DL assessed these items using Likert scales, with two survey rounds to refine responses and gauge consensus. We also employed the content validity ratio with a cutoff of 0.59 to determine item face and content validity. Round 1 included a 27-item questionnaire, with",
      "num_citations": 3,
      "url": "https://link.springer.com/article/10.1007/s10278-024-01065-2",
      "article_id": "checklist-for-reproducibility-of-deep-le-14401134",
      "bibtex": "@article{faghani2024checklist,\n    author = {Mana Moassefi and Yashbir Singh and Gian Marco Conte and Bardia Khosravi and Pouria Rouzrokh and Sanaz Vahdati and Nabile Safdar and Linda Moy and Felipe Kitamura and Amilcare Gentili and Paras Lakhani and Nina Kottler and Safwan S Halabi and Joseph H Yacoub and Yuankai Hou and Khaled Younis and Bradley J Erickson and Elizabeth Krupinski and Shahriar Faghani},\n    title = {Checklist for reproducibility of deep learning in medical imaging},\n    year = {2024},\n    volume = {37},\n    number = {4},\n    pages = {1664-1673},\n    note = {checklist-for-reproducibility-of-deep-le-14401134},\n    url = {https://link.springer.com/article/10.1007/s10278-024-01065-2},\n    abstract = {The application of deep learning (DL) in medicine introduces transformative tools with the potential to enhance prognosis, diagnosis, and treatment planning. However, ensuring transparent documentation is essential for researchers to enhance reproducibility and refine techniques. Our study addresses the unique challenges presented by DL in medical imaging by developing a comprehensive checklist using the Delphi method to enhance reproducibility and reliability in this dynamic field. We compiled a preliminary checklist based on a comprehensive review of existing checklists and relevant literature. A panel of 11 experts in medical imaging and DL assessed these items using Likert scales, with two survey rounds to refine responses and gauge consensus. We also employed the content validity ratio with a cutoff of 0.59 to determine item face and content validity. Round 1 included a 27-item questionnaire, with},\n}"
    },
    {
      "title": "A multi-view deep learning model for thyroid nodules detection and characterization in ultrasound imaging",
      "authors": "Sanaz Vahdati, Bardia Khosravi, Kathryn A Robinson, Pouria Rouzrokh, Mana Moassefi, Zeynettin Akkus, Bradley J Erickson",
      "year": 2024,
      "journal": "Bioengineering",
      "volume": "11",
      "number": "7",
      "pages": "648",
      "abstract": "Thyroid Ultrasound (US) is the primary method to evaluate thyroid nodules. Deep learning (DL) has been playing a significant role in evaluating thyroid cancer. We propose a DL-based pipeline to detect and classify thyroid nodules into benign or malignant groups relying on two views of US imaging. Transverse and longitudinal US images of thyroid nodules from 983 patients were collected retrospectively. Eighty-one cases were held out as a testing set, and the rest of the data were used in five-fold cross-validation (CV). Two You Look Only Once (YOLO) v5 models were trained to detect nodules and classify them. For each view, five models were developed during the CV, which was ensembled by using non-max suppression (NMS) to boost their collective generalizability. An extreme gradient boosting (XGBoost) model was trained on the outputs of the ensembled models for both views to yield a final prediction of malignancy for each nodule. The test set was evaluated by an expert radiologist using the American College of Radiology Thyroid Imaging Reporting and Data System (ACR-TIRADS). The ensemble models for each view achieved a mAP0.5 of 0.797 (transverse) and 0.716 (longitudinal). The whole pipeline reached an AUROC of 0.84 (CI 95: 0.750.91) with sensitivity and specificity of 84 and 63, respectively, while the ACR-TIRADS evaluation of the same set had a sensitivity of 76 and specificity of 34 (p-value 0.003). Our proposed work demonstrated the potential possibility of a deep learning model to achieve diagnostic performance for thyroid nodule evaluation.",
      "num_citations": 7,
      "url": "https://www.mdpi.com/2306-5354/11/7/648",
      "article_id": "a-multi-view-deep-learning-model-for-thy-4d6ea65e",
      "bibtex": "@article{erickson2024a,\n    author = {Sanaz Vahdati and Bardia Khosravi and Kathryn A Robinson and Pouria Rouzrokh and Mana Moassefi and Zeynettin Akkus and Bradley J Erickson},\n    title = {A multi-view deep learning model for thyroid nodules detection and characterization in ultrasound imaging},\n    year = {2024},\n    journal = {Bioengineering},\n    volume = {11},\n    number = {7},\n    pages = {648},\n    note = {a-multi-view-deep-learning-model-for-thy-4d6ea65e},\n    url = {https://www.mdpi.com/2306-5354/11/7/648},\n    abstract = {Thyroid Ultrasound (US) is the primary method to evaluate thyroid nodules. Deep learning (DL) has been playing a significant role in evaluating thyroid cancer. We propose a DL-based pipeline to detect and classify thyroid nodules into benign or malignant groups relying on two views of US imaging. Transverse and longitudinal US images of thyroid nodules from 983 patients were collected retrospectively. Eighty-one cases were held out as a testing set, and the rest of the data were used in five-fold cross-validation (CV). Two You Look Only Once (YOLO) v5 models were trained to detect nodules and classify them. For each view, five models were developed during the CV, which was ensembled by using non-max suppression (NMS) to boost their collective generalizability. An extreme gradient boosting (XGBoost) model was trained on the outputs of the ensembled models for both views to yield a final prediction of malignancy for each nodule. The test set was evaluated by an expert radiologist using the American College of Radiology Thyroid Imaging Reporting and Data System (ACR-TIRADS). The ensemble models for each view achieved a mAP0.5 of 0.797 (transverse) and 0.716 (longitudinal). The whole pipeline reached an AUROC of 0.84 (CI 95: 0.750.91) with sensitivity and specificity of 84 and 63, respectively, while the ACR-TIRADS evaluation of the same set had a sensitivity of 76 and specificity of 34 (p-value 0.003). Our proposed work demonstrated the potential possibility of a deep learning model to achieve diagnostic performance for thyroid nodule evaluation.},\n}"
    },
    {
      "title": "Analyzing Racial Differences in Imaging Joint Replacement Registries Using Generative Artificial Intelligence: Advancing Orthopaedic Data Equity",
      "authors": "Bardia Khosravi, Pouria Rouzrokh, Bradley J Erickson, Hillary W Garner, Doris E Wenger, Michael J Taunton, Cody C Wyles",
      "year": 2024,
      "journal": "Arthroplasty Today",
      "volume": "29",
      "pages": "101503",
      "abstract": "BackgroundDiscrepancies in medical data sets can perpetuate bias, especially when training deep learning models, potentially leading to biased outcomes in clinical applications. Understanding these biases is crucial for the development of equitable healthcare technologies. This study employs generative deep learning technology to explore and understand radiographic differences based on race among patients undergoing total hip arthroplasty.MethodsUtilizing a large institutional registry, we retrospectively analyzed pelvic radiographs from total hip arthroplasty patients, characterized by demographics and image features. Denoising diffusion probabilistic models generated radiographs conditioned on demographic and imaging characteristics. Fr\u00e9chet Inception Distance assessed the generated image quality, showing the diversity and realism of the generated images. Sixty transition videos were generated that",
      "num_citations": 6,
      "url": "https://www.sciencedirect.com/science/article/pii/S2352344124001882",
      "article_id": "analyzing-racial-differences-in-imaging--d81d4389",
      "bibtex": "@article{wyles2024analyzing,\n    author = {Bardia Khosravi and Pouria Rouzrokh and Bradley J Erickson and Hillary W Garner and Doris E Wenger and Michael J Taunton and Cody C Wyles},\n    title = {Analyzing Racial Differences in Imaging Joint Replacement Registries Using Generative Artificial Intelligence: Advancing Orthopaedic Data Equity},\n    year = {2024},\n    journal = {Arthroplasty Today},\n    volume = {29},\n    pages = {101503},\n    note = {analyzing-racial-differences-in-imaging--d81d4389},\n    url = {https://www.sciencedirect.com/science/article/pii/S2352344124001882},\n    abstract = {BackgroundDiscrepancies in medical data sets can perpetuate bias, especially when training deep learning models, potentially leading to biased outcomes in clinical applications. Understanding these biases is crucial for the development of equitable healthcare technologies. This study employs generative deep learning technology to explore and understand radiographic differences based on race among patients undergoing total hip arthroplasty.MethodsUtilizing a large institutional registry, we retrospectively analyzed pelvic radiographs from total hip arthroplasty patients, characterized by demographics and image features. Denoising diffusion probabilistic models generated radiographs conditioned on demographic and imaging characteristics. Fr\u00e9chet Inception Distance assessed the generated image quality, showing the diversity and realism of the generated images. Sixty transition videos were generated that},\n}"
    },
    {
      "title": "CONFLARE: CONFormal LArge language model REtrieval",
      "authors": "Pouria Rouzrokh, Shahriar Faghani, Cooper U Gamble, Moein Shariatnia, Bradley J Erickson",
      "year": 2024,
      "journal": "arXiv preprint arXiv:2404.04287",
      "abstract": "Retrieval-augmented generation (RAG) frameworks enable large language models (LLMs) to retrieve relevant information from a knowledge base and incorporate it into the context for generating responses. This mitigates hallucinations and allows for the updating of knowledge without retraining the LLM. However, RAG does not guarantee valid responses if retrieval fails to identify the necessary information as the context for response generation. Also, if there is contradictory content, the RAG response will likely reflect only one of the two possible responses. Therefore, quantifying uncertainty in the retrieval process is crucial for ensuring RAG trustworthiness. In this report, we introduce a four-step framework for applying conformal prediction to quantify retrieval uncertainty in RAG frameworks. First, a calibration set of questions answerable from the knowledge base is constructed. Each question's embedding is compared against document embeddings to identify the most relevant document chunks containing the answer and record their similarity scores. Given a user-specified error rate (alpha), these similarity scores are then analyzed to determine a similarity score cutoff threshold. During inference, all chunks with similarity exceeding this threshold are retrieved to provide context to the LLM, ensuring the true answer is captured in the context with a (1-alpha) confidence level. We provide a Python package that enables users to implement the entire workflow proposed in our work, only using LLMs and without human intervention.",
      "num_citations": 5,
      "url": "https://arxiv.org/abs/2404.04287",
      "article_id": "conflare-conformal-large-language-model--6eb7c1cb",
      "bibtex": "@article{erickson2024conflare,\n    author = {Pouria Rouzrokh and Shahriar Faghani and Cooper U Gamble and Moein Shariatnia and Bradley J Erickson},\n    title = {CONFLARE: CONFormal LArge language model REtrieval},\n    year = {2024},\n    journal = {arXiv preprint arXiv:2404.04287},\n    note = {conflare-conformal-large-language-model--6eb7c1cb},\n    url = {https://arxiv.org/abs/2404.04287},\n    abstract = {Retrieval-augmented generation (RAG) frameworks enable large language models (LLMs) to retrieve relevant information from a knowledge base and incorporate it into the context for generating responses. This mitigates hallucinations and allows for the updating of knowledge without retraining the LLM. However, RAG does not guarantee valid responses if retrieval fails to identify the necessary information as the context for response generation. Also, if there is contradictory content, the RAG response will likely reflect only one of the two possible responses. Therefore, quantifying uncertainty in the retrieval process is crucial for ensuring RAG trustworthiness. In this report, we introduce a four-step framework for applying conformal prediction to quantify retrieval uncertainty in RAG frameworks. First, a calibration set of questions answerable from the knowledge base is constructed. Each question's embedding is compared against document embeddings to identify the most relevant document chunks containing the answer and record their similarity scores. Given a user-specified error rate (alpha), these similarity scores are then analyzed to determine a similarity score cutoff threshold. During inference, all chunks with similarity exceeding this threshold are retrieved to provide context to the LLM, ensuring the true answer is captured in the context with a (1-alpha) confidence level. We provide a Python package that enables users to implement the entire workflow proposed in our work, only using LLMs and without human intervention.},\n}"
    },
    {
      "title": "A guideline for open-source tools to make medical imaging data ready for artificial intelligence applications: A society of imaging informatics in medicine (siim) survey",
      "authors": "Sanaz Vahdati, Bardia Khosravi, Elham Mahmoudi, Kuan Zhang, Pouria Rouzrokh, Shahriar Faghani, Mana Moassefi, Aylin Tahmasebi, Katherine P Andriole, Peter Chang, Keyvan Farahani, Mona G Flores, Les Folio, Sina Houshmand, Maryellen L Giger, Judy W Gichoya, Bradley J Erickson",
      "year": 2024,
      "journal": "Journal of Imaging Informatics in Medicine",
      "volume": "37",
      "number": "5",
      "pages": "2015-2024",
      "abstract": "In recent years, the role of Artificial Intelligence (AI) in medical imaging has become increasingly prominent, with the majority of AI applications approved by the FDA being in imaging and radiology in 2023. The surge in AI model development to tackle clinical challenges underscores the necessity for preparing high-quality medical imaging data. Proper data preparation is crucial as it fosters the creation of standardized and reproducible AI models while minimizing biases. Data curation transforms raw data into a valuable, organized, and dependable resource and is a fundamental process to the success of machine learning and analytical projects. Considering the plethora of available tools for data curation in different stages, it is crucial to stay informed about the most relevant tools within specific research areas. In the current work, we propose a descriptive outline for different steps of data curation while we furnish",
      "num_citations": 4,
      "url": "https://link.springer.com/article/10.1007/s10278-024-01083-0",
      "article_id": "a-guideline-for-open-source-tools-to-mak-6356759c",
      "bibtex": "@article{erickson2024a,\n    author = {Sanaz Vahdati and Bardia Khosravi and Elham Mahmoudi and Kuan Zhang and Pouria Rouzrokh and Shahriar Faghani and Mana Moassefi and Aylin Tahmasebi and Katherine P Andriole and Peter Chang and Keyvan Farahani and Mona G Flores and Les Folio and Sina Houshmand and Maryellen L Giger and Judy W Gichoya and Bradley J Erickson},\n    title = {A guideline for open-source tools to make medical imaging data ready for artificial intelligence applications: A society of imaging informatics in medicine (siim) survey},\n    year = {2024},\n    journal = {Journal of Imaging Informatics in Medicine},\n    volume = {37},\n    number = {5},\n    pages = {2015-2024},\n    note = {a-guideline-for-open-source-tools-to-mak-6356759c},\n    url = {https://link.springer.com/article/10.1007/s10278-024-01083-0},\n    abstract = {In recent years, the role of Artificial Intelligence (AI) in medical imaging has become increasingly prominent, with the majority of AI applications approved by the FDA being in imaging and radiology in 2023. The surge in AI model development to tackle clinical challenges underscores the necessity for preparing high-quality medical imaging data. Proper data preparation is crucial as it fosters the creation of standardized and reproducible AI models while minimizing biases. Data curation transforms raw data into a valuable, organized, and dependable resource and is a fundamental process to the success of machine learning and analytical projects. Considering the plethora of available tools for data curation in different stages, it is crucial to stay informed about the most relevant tools within specific research areas. In the current work, we propose a descriptive outline for different steps of data curation while we furnish},\n}"
    },
    {
      "title": "Preparing Radiologists for an Artificial Intelligence\u2013enhanced Future: Tips for Trainees",
      "authors": "Pouria Rouzrokh, Jamie E Clarke, Melina Hosseiny, Moozhan Nikpanah, Mahati Mokkarala",
      "year": 2024,
      "volume": "44",
      "number": "8",
      "pages": "e240042",
      "abstract": "Artificial intelligence (AI) has seen escalating interest in the field of radiology over the past few years. Meanwhile, a critical but less discussed issue is the preparation of trainees for an AI-enhanced future. Surveys indicate that while trainees are eager to learn about AI, they have uncertainties about its capabilities, potential threat to job security, and application in clinical practice (1). Addressing such uncertainties is essential; however, educating trainees on AI presents significant challenges. First, not every radiology program has faculty members with expertise in data science, nor do all have the financial means for comprehensive training from external sources. Second, despite various efforts to educate trainees on AI (2), there is no current consensus on a strategy that effectively aligns with the rapid advancements in AI without burdening the already comprehensive radiology residency curricula. Despite the ongoing",
      "num_citations": 3,
      "url": "https://pubs.rsna.org/doi/full/10.1148/rg.240042",
      "article_id": "preparing-radiologists-for-an-artificial-e9752c6c",
      "bibtex": "@article{mokkarala2024preparing,\n    author = {Pouria Rouzrokh and Jamie E Clarke and Melina Hosseiny and Moozhan Nikpanah and Mahati Mokkarala},\n    title = {Preparing Radiologists for an Artificial Intelligence\u2013enhanced Future: Tips for Trainees},\n    year = {2024},\n    volume = {44},\n    number = {8},\n    pages = {e240042},\n    note = {preparing-radiologists-for-an-artificial-e9752c6c},\n    url = {https://pubs.rsna.org/doi/full/10.1148/rg.240042},\n    abstract = {Artificial intelligence (AI) has seen escalating interest in the field of radiology over the past few years. Meanwhile, a critical but less discussed issue is the preparation of trainees for an AI-enhanced future. Surveys indicate that while trainees are eager to learn about AI, they have uncertainties about its capabilities, potential threat to job security, and application in clinical practice (1). Addressing such uncertainties is essential; however, educating trainees on AI presents significant challenges. First, not every radiology program has faculty members with expertise in data science, nor do all have the financial means for comprehensive training from external sources. Second, despite various efforts to educate trainees on AI (2), there is no current consensus on a strategy that effectively aligns with the rapid advancements in AI without burdening the already comprehensive radiology residency curricula. Despite the ongoing},\n}"
    },
    {
      "title": "Invited commentary: the double-edged sword of bias in medical imaging artificial intelligence",
      "authors": "Pouria Rouzrokh, Bradley J Erickson",
      "year": 2024,
      "journal": "RadioGraphics",
      "volume": "44",
      "number": "5",
      "pages": "e230243",
      "abstract": "It is our great pleasure to write this commentary on the excellent article by Tejani et al (1) on understanding and mitigating unwanted bias in artificial intelligence (AI) tools applied to medical imaging. The authors provide a comprehensive discussion on how bias could be defined from statistical, cognitive, and social perspectives. Additionally, they review how each of these perspectives can help detect and mitigate some of the common flaws that can occur during planning, development, evaluation, and short-or long-term deployment of AI tools in radiology. While the importance of detecting and mitigating unwanted bias in radiology AI has been extensively discussed in prior technical literature (14), the main advantage of the present work is in how the authors introduce their content in a language that can be understood by readers with a wide range of technical expertise. While reading this article will certainly",
      "num_citations": 2,
      "url": "https://pubs.rsna.org/doi/full/10.1148/rg.230243",
      "article_id": "invited-commentary-the-double-edged-swor-c97fbddd",
      "bibtex": "@article{erickson2024invited,\n    author = {Pouria Rouzrokh and Bradley J Erickson},\n    title = {Invited commentary: the double-edged sword of bias in medical imaging artificial intelligence},\n    year = {2024},\n    journal = {RadioGraphics},\n    volume = {44},\n    number = {5},\n    pages = {e230243},\n    note = {invited-commentary-the-double-edged-swor-c97fbddd},\n    url = {https://pubs.rsna.org/doi/full/10.1148/rg.230243},\n    abstract = {It is our great pleasure to write this commentary on the excellent article by Tejani et al (1) on understanding and mitigating unwanted bias in artificial intelligence (AI) tools applied to medical imaging. The authors provide a comprehensive discussion on how bias could be defined from statistical, cognitive, and social perspectives. Additionally, they review how each of these perspectives can help detect and mitigate some of the common flaws that can occur during planning, development, evaluation, and short-or long-term deployment of AI tools in radiology. While the importance of detecting and mitigating unwanted bias in radiology AI has been extensively discussed in prior technical literature (14), the main advantage of the present work is in how the authors introduce their content in a language that can be understood by readers with a wide range of technical expertise. While reading this article will certainly},\n}"
    },
    {
      "title": "Development of a deep learning model for the automated detection of green pixels indicative of gout on dual energy CT scan",
      "authors": "Shahriar Faghani, Rhodes G Nicholas, Soham Patel, Francis I Baffour, Mana Moassefi, Pouria Rouzrokh, Bardia Khosravi, Garret M Powell, Shuai Leng, Katrina N Glazebrook, Bradley J Erickson, Christin A Tiegs-Heiden",
      "year": 2024,
      "journal": "Research in Diagnostic and Interventional Imaging",
      "volume": "9",
      "pages": "100044",
      "abstract": "Dual-energy CT (DECT) is a non-invasive way to determine the presence of monosodium urate (MSU) crystals in the workup of gout. Color-coding distinguishes MSU from calcium following material decomposition and post-processing. Most software labels MSU as green and calcium as blue. There are limitations in the current image processing methods of segmenting green-encoded pixels. Additionally, identifying green foci is tedious, and automated detection would improve workflow. This study aimed to determine the optimal deep learning (DL) algorithm for segmenting green-encoded pixels of MSU crystals on DECTs.DECT images of positive and negative gout cases were retrospectively collected. The dataset was split into train (N 28) and held-out test (N 30) sets. To perform cross-validation, the train set was split into seven folds. The images were presented to two musculoskeletal",
      "num_citations": 2,
      "url": "https://www.sciencedirect.com/science/article/pii/S277265252400005X",
      "article_id": "development-of-a-deep-learning-model-for-b6e87ca2",
      "bibtex": "@article{tiegsheiden2024development,\n    author = {Shahriar Faghani and Rhodes G Nicholas and Soham Patel and Francis I Baffour and Mana Moassefi and Pouria Rouzrokh and Bardia Khosravi and Garret M Powell and Shuai Leng and Katrina N Glazebrook and Bradley J Erickson and Christin A Tiegs-Heiden},\n    title = {Development of a deep learning model for the automated detection of green pixels indicative of gout on dual energy CT scan},\n    year = {2024},\n    journal = {Research in Diagnostic and Interventional Imaging},\n    volume = {9},\n    pages = {100044},\n    note = {development-of-a-deep-learning-model-for-b6e87ca2},\n    url = {https://www.sciencedirect.com/science/article/pii/S277265252400005X},\n    abstract = {Dual-energy CT (DECT) is a non-invasive way to determine the presence of monosodium urate (MSU) crystals in the workup of gout. Color-coding distinguishes MSU from calcium following material decomposition and post-processing. Most software labels MSU as green and calcium as blue. There are limitations in the current image processing methods of segmenting green-encoded pixels. Additionally, identifying green foci is tedious, and automated detection would improve workflow. This study aimed to determine the optimal deep learning (DL) algorithm for segmenting green-encoded pixels of MSU crystals on DECTs.DECT images of positive and negative gout cases were retrospectively collected. The dataset was split into train (N 28) and held-out test (N 30) sets. To perform cross-validation, the train set was split into seven folds. The images were presented to two musculoskeletal},\n}"
    },
    {
      "title": "Deep learning classification of pediatric spinal radiographs for use in large scale imaging registries",
      "authors": "Kellen L Mulford, Christina M Regan, Julia E Todderud, Charles P Nolte Jr, Zachariah Pinter, Connie Chang-Chien, Shi Yan, Cody Wyles, Bardia Khosravi, Pouria Rouzrokh, Hilal Maradit Kremers, A Noelle Larson",
      "year": 2024,
      "journal": "Spine deformity",
      "volume": "12",
      "number": "6",
      "pages": "1607-1614",
      "abstract": "The purpose of this study is to develop and apply an algorithm that automatically classifies spine radiographs of pediatric scoliosis patients.Anteriorposterior (AP) and lateral spine radiographs were extracted from the institutional picture archive for patients with scoliosis. Overall, there were 7777 AP images and 5621 lateral images. Radiographs were manually classified into ten categories: two preoperative and three postoperative categories each for AP and lateral images. The images were split into training, validation, and testing sets (70:15:15 proportional split). A deep learning classifier using the EfficientNet B6 architecture was trained on the spine training set. Hyperparameters and model architecture were tuned against the performance of the models in the validation set.The trained classifiers had an overall accuracy on the test set of 1.00 on 1166 AP images and 1.00 on 843 lateral",
      "num_citations": 2,
      "url": "https://link.springer.com/article/10.1007/s43390-024-00933-9",
      "article_id": "deep-learning-classification-of-pediatri-9bd6388f",
      "bibtex": "@article{larson2024deep,\n    author = {Kellen L Mulford and Christina M Regan and Julia E Todderud and Charles P Nolte Jr and Zachariah Pinter and Connie Chang-Chien and Shi Yan and Cody Wyles and Bardia Khosravi and Pouria Rouzrokh and Hilal Maradit Kremers and A Noelle Larson},\n    title = {Deep learning classification of pediatric spinal radiographs for use in large scale imaging registries},\n    year = {2024},\n    journal = {Spine deformity},\n    volume = {12},\n    number = {6},\n    pages = {1607-1614},\n    note = {deep-learning-classification-of-pediatri-9bd6388f},\n    url = {https://link.springer.com/article/10.1007/s43390-024-00933-9},\n    abstract = {The purpose of this study is to develop and apply an algorithm that automatically classifies spine radiographs of pediatric scoliosis patients.Anteriorposterior (AP) and lateral spine radiographs were extracted from the institutional picture archive for patients with scoliosis. Overall, there were 7777 AP images and 5621 lateral images. Radiographs were manually classified into ten categories: two preoperative and three postoperative categories each for AP and lateral images. The images were split into training, validation, and testing sets (70:15:15 proportional split). A deep learning classifier using the EfficientNet B6 architecture was trained on the spine training set. Hyperparameters and model architecture were tuned against the performance of the models in the validation set.The trained classifiers had an overall accuracy on the test set of 1.00 on 1166 AP images and 1.00 on 843 lateral},\n}"
    },
    {
      "title": "The era of artificial intelligence in radiology: how to prepare for a different future",
      "authors": "Pouria Rouzrokh, Omer A Awan",
      "year": 2024,
      "journal": "Academic Radiology",
      "volume": "31",
      "number": "11",
      "pages": "4726-4728",
      "abstract": "I magine a scenario where you, as an attending radiologist, are evaluating a patients mammogram with a first-year radiology resident. The resident interrupts your reading to inquire about your thoughts on a recent artificial intelligence (AI) tool for breast cancer detection on mammograms. The resident characterizes the tool as exemplary and provides you with statistics from an article she has read demonstrating that the AI model has significantly outperformed radiologists in detecting suspicious lesions. She then pauses for a few seconds before concluding:\" I am uncertain if radiologists still have a position in medicine in light of the daily introduction of new AI capabilities. If these tools are superior to radiologists, won't they replace them? AI refers to all computer technologies capable of simulating human performance. With this broad definition, AI has been in radiology since the dawn of the computer era. Early AI had",
      "num_citations": 1,
      "url": "https://www.academicradiology.org/article/S1076-6332(23)00701-8/abstract",
      "article_id": "the-era-of-artificial-intelligence-in-ra-b964bad5",
      "bibtex": "@article{awan2024the,\n    author = {Pouria Rouzrokh and Omer A Awan},\n    title = {The era of artificial intelligence in radiology: how to prepare for a different future},\n    year = {2024},\n    journal = {Academic Radiology},\n    volume = {31},\n    number = {11},\n    pages = {4726-4728},\n    note = {the-era-of-artificial-intelligence-in-ra-b964bad5},\n    url = {https://www.academicradiology.org/article/S1076-6332(23)00701-8/abstract},\n    abstract = {I magine a scenario where you, as an attending radiologist, are evaluating a patients mammogram with a first-year radiology resident. The resident interrupts your reading to inquire about your thoughts on a recent artificial intelligence (AI) tool for breast cancer detection on mammograms. The resident characterizes the tool as exemplary and provides you with statistics from an article she has read demonstrating that the AI model has significantly outperformed radiologists in detecting suspicious lesions. She then pauses for a few seconds before concluding:\" I am uncertain if radiologists still have a position in medicine in light of the daily introduction of new AI capabilities. If these tools are superior to radiologists, won't they replace them? AI refers to all computer technologies capable of simulating human performance. With this broad definition, AI has been in radiology since the dawn of the computer era. Early AI had},\n}"
    },
    {
      "title": "A stepwise approach to analyzing musculoskeletal imaging data with artificial intelligence",
      "authors": "John P Mickley, Austin F Grove, Pouria Rouzrokh, Linjun Yang, A Noelle Larson, Joaquin Sanchez\u2010Sotello, Hilal Maradit Kremers, Cody C Wyles",
      "year": 2024,
      "journal": "Arthritis Care & Research",
      "volume": "76",
      "number": "5",
      "pages": "590-599",
      "abstract": "The digitization of medical records and expanding electronic health records has created an era of Big Data with an abundance of available information ranging from clinical notes to imaging studies. In the field of rheumatology, medical imaging is used to guide both diagnosis and treatment of a wide variety of rheumatic conditions. Although there is an abundance of data to analyze, traditional methods of image analysis are human resource intensive. Fortunately, the growth of artificial intelligence (AI) may be a solution to handle large datasets. In particular, computer vision is a field within AI that analyzes images and extracts information. Computer vision has impressive capabilities and can be applied to rheumatologic conditions, necessitating a need to understand how computer vision works. In this article, we provide an overview of AI in rheumatology and conclude with a five step process to plan and conduct",
      "num_citations": 3,
      "url": "https://acrjournals.onlinelibrary.wiley.com/doi/abs/10.1002/acr.25260",
      "article_id": "a-stepwise-approach-to-analyzing-musculo-33d3e11f",
      "bibtex": "@article{wyles2024a,\n    author = {John P Mickley and Austin F Grove and Pouria Rouzrokh and Linjun Yang and A Noelle Larson and Joaquin Sanchez\u2010Sotello and Hilal Maradit Kremers and Cody C Wyles},\n    title = {A stepwise approach to analyzing musculoskeletal imaging data with artificial intelligence},\n    year = {2024},\n    journal = {Arthritis Care \\& Research},\n    volume = {76},\n    number = {5},\n    pages = {590-599},\n    note = {a-stepwise-approach-to-analyzing-musculo-33d3e11f},\n    url = {https://acrjournals.onlinelibrary.wiley.com/doi/abs/10.1002/acr.25260},\n    abstract = {The digitization of medical records and expanding electronic health records has created an era of Big Data with an abundance of available information ranging from clinical notes to imaging studies. In the field of rheumatology, medical imaging is used to guide both diagnosis and treatment of a wide variety of rheumatic conditions. Although there is an abundance of data to analyze, traditional methods of image analysis are human resource intensive. Fortunately, the growth of artificial intelligence (AI) may be a solution to handle large datasets. In particular, computer vision is a field within AI that analyzes images and extracts information. Computer vision has impressive capabilities and can be applied to rheumatologic conditions, necessitating a need to understand how computer vision works. In this article, we provide an overview of AI in rheumatology and conclude with a five step process to plan and conduct},\n}"
    },
    {
      "title": "Characterizing hip joint morphology using a multitask deep learning model",
      "authors": "Bardia Khosravi, Lainey G Bukowiec, John P Mickley, Jacob F Oeding, Pouria Rouzrokh, Bradley J Erickson, Rafael J Sierra, Michael J Taunton, Emmanouil Grigoriou, Cody C Wyles",
      "year": 2024,
      "pages": "hnae041",
      "abstract": "Deep learning is revolutionizing medical imaging analysis by enabling the classification of various pathoanatomical conditions at scale. Unfortunately, there have been a limited number of accurate and efficient machine learning (ML) algorithms that have been developed for the diagnostic workup of morphological hip pathologies, including developmental dysplasia of the hip and femoroacetabular impingement. The current study reports on the performance of a novel ML model with YOLOv5 and ConvNeXt-Tiny architecture in predicting the morphological features of these conditions, including cam deformity, ischial spine sign, dysplastic appearance, and other abnormalities. The model achieved 78.0 accuracy for detecting cam deformity, 87.2 for ischial spine sign, 76.6 for dysplasia, and 71.6 for all abnormalities combined. The model achieved an Area under the Receiver Operating Curve of 0.89 for",
      "num_citations": 2,
      "url": "https://academic.oup.com/jhps/advance-article-abstract/doi/10.1093/jhps/hnae041/7922539",
      "article_id": "characterizing-hip-joint-morphology-usin-0faa7a8b",
      "bibtex": "@article{wyles2024characterizing,\n    author = {Bardia Khosravi and Lainey G Bukowiec and John P Mickley and Jacob F Oeding and Pouria Rouzrokh and Bradley J Erickson and Rafael J Sierra and Michael J Taunton and Emmanouil Grigoriou and Cody C Wyles},\n    title = {Characterizing hip joint morphology using a multitask deep learning model},\n    year = {2024},\n    pages = {hnae041},\n    note = {characterizing-hip-joint-morphology-usin-0faa7a8b},\n    url = {https://academic.oup.com/jhps/advance-article-abstract/doi/10.1093/jhps/hnae041/7922539},\n    abstract = {Deep learning is revolutionizing medical imaging analysis by enabling the classification of various pathoanatomical conditions at scale. Unfortunately, there have been a limited number of accurate and efficient machine learning (ML) algorithms that have been developed for the diagnostic workup of morphological hip pathologies, including developmental dysplasia of the hip and femoroacetabular impingement. The current study reports on the performance of a novel ML model with YOLOv5 and ConvNeXt-Tiny architecture in predicting the morphological features of these conditions, including cam deformity, ischial spine sign, dysplastic appearance, and other abnormalities. The model achieved 78.0 accuracy for detecting cam deformity, 87.2 for ischial spine sign, 76.6 for dysplasia, and 71.6 for all abnormalities combined. The model achieved an Area under the Receiver Operating Curve of 0.89 for},\n}"
    },
    {
      "title": "Impact of Leg Position on Measurements Used to Detect Femoral Component Subsidence in THA",
      "authors": "Elizabeth S Kaji, Austin F Grove, Eva Lehtonen, Kellen L Mulford, Pouria Rouzrokh, Charles P Hannon, Michael J Taunton, Cody C Wyles",
      "year": 2024,
      "journal": "Arthroplasty Today",
      "volume": "30",
      "pages": "101553",
      "abstract": "BackgroundA fully automated artificial intelligencebased tool was developed to detect and quantify femoral component subsidence between serial radiographs. However, it did not account for measurement errors due to leg position differences, such as rotation or flexion, between comparative radiographs. If there are small differences in rotation or flexion of the leg between comparative radiographs, the impact on subsidence measurement is unclear.MethodsTwenty-five primary total hip arthroplasty procedures were performed by 3 fellowship-trained arthroplasty surgeons using a direct anterior approach. A Hana table allowed precise changes in femur position. Final fluoroscopic images were collected with rotational and flexion changes applied to the femur without moving the C-arm. Subsidence values were manually measured and compared across different positions.ResultsVariations in greater trochanter to tip",
      "num_citations": 0,
      "url": "https://www.sciencedirect.com/science/article/pii/S2352344124002383",
      "article_id": "impact-of-leg-position-on-measurements-u-5e78b11b",
      "bibtex": "@article{wyles2024impact,\n    author = {Elizabeth S Kaji and Austin F Grove and Eva Lehtonen and Kellen L Mulford and Pouria Rouzrokh and Charles P Hannon and Michael J Taunton and Cody C Wyles},\n    title = {Impact of Leg Position on Measurements Used to Detect Femoral Component Subsidence in THA},\n    year = {2024},\n    journal = {Arthroplasty Today},\n    volume = {30},\n    pages = {101553},\n    note = {impact-of-leg-position-on-measurements-u-5e78b11b},\n    url = {https://www.sciencedirect.com/science/article/pii/S2352344124002383},\n    abstract = {BackgroundA fully automated artificial intelligencebased tool was developed to detect and quantify femoral component subsidence between serial radiographs. However, it did not account for measurement errors due to leg position differences, such as rotation or flexion, between comparative radiographs. If there are small differences in rotation or flexion of the leg between comparative radiographs, the impact on subsidence measurement is unclear.MethodsTwenty-five primary total hip arthroplasty procedures were performed by 3 fellowship-trained arthroplasty surgeons using a direct anterior approach. A Hana table allowed precise changes in femur position. Final fluoroscopic images were collected with rotational and flexion changes applied to the femur without moving the C-arm. Subsidence values were manually measured and compared across different positions.ResultsVariations in greater trochanter to tip},\n}"
    },
    {
      "title": "RIDGE: Reproducibility, Integrity, Dependability, Generalizability, and Efficiency Assessment of Medical Image Segmentation Models",
      "authors": "Farhad Maleki, Linda Moy, Reza Forghani, Tapotosh Ghosh, Katie Ovens, Steve Langer, Pouria Rouzrokh, Bardia Khosravi, Ali Ganjizadeh, Daniel Warren, Roxana Daneshjou, Mana Moassefi, Atlas Haddadi Avval, Susan Sotardi, Neil Tenenholtz, Felipe Kitamura, Timothy Kline",
      "year": 2024,
      "journal": "Journal of Imaging Informatics in Medicine",
      "pages": "1-13",
      "abstract": "Deep learning techniques hold immense promise for advancing medical image analysis, particularly in tasks like image segmentation, where precise annotation of regions or volumes of interest within medical images is crucial but manually laborious and prone to interobserver and intraobserver biases. As such, deep learning approaches could provide automated solutions for such applications. However, the potential of these techniques is often undermined by challenges in reproducibility and generalizability, which are key barriers to their clinical adoption. This paper introduces the RIDGE checklist, a comprehensive framework designed to assess the Reproducibility, Integrity, Dependability, Generalizability, and Efficiency of deep learning-based medical image segmentation models. The RIDGE checklist is not just a tool for evaluation but also a guideline for researchers striving to improve the quality and",
      "num_citations": 2,
      "url": "https://link.springer.com/article/10.1007/s10278-024-01282-9",
      "article_id": "ridge-reproducibility-integrity-dependab-657d4a0f",
      "bibtex": "@article{kline2024ridge,\n    author = {Farhad Maleki and Linda Moy and Reza Forghani and Tapotosh Ghosh and Katie Ovens and Steve Langer and Pouria Rouzrokh and Bardia Khosravi and Ali Ganjizadeh and Daniel Warren and Roxana Daneshjou and Mana Moassefi and Atlas Haddadi Avval and Susan Sotardi and Neil Tenenholtz and Felipe Kitamura and Timothy Kline},\n    title = {RIDGE: Reproducibility, Integrity, Dependability, Generalizability, and Efficiency Assessment of Medical Image Segmentation Models},\n    year = {2024},\n    journal = {Journal of Imaging Informatics in Medicine},\n    pages = {1-13},\n    note = {ridge-reproducibility-integrity-dependab-657d4a0f},\n    url = {https://link.springer.com/article/10.1007/s10278-024-01282-9},\n    abstract = {Deep learning techniques hold immense promise for advancing medical image analysis, particularly in tasks like image segmentation, where precise annotation of regions or volumes of interest within medical images is crucial but manually laborious and prone to interobserver and intraobserver biases. As such, deep learning approaches could provide automated solutions for such applications. However, the potential of these techniques is often undermined by challenges in reproducibility and generalizability, which are key barriers to their clinical adoption. This paper introduces the RIDGE checklist, a comprehensive framework designed to assess the Reproducibility, Integrity, Dependability, Generalizability, and Efficiency of deep learning-based medical image segmentation models. The RIDGE checklist is not just a tool for evaluation but also a guideline for researchers striving to improve the quality and},\n}"
    },
    {
      "title": "Exploring the Effect of Domain-Specific Transfer Learning for Thyroid Nodule Classification",
      "authors": "Sanaz Vahdati, Bardia Khosravi, Pouria Rouzrokh, Bradley J Erickson",
      "year": 2024,
      "journal": "Journal of the American College of Radiology",
      "volume": "21",
      "number": "11",
      "pages": "1796-1799",
      "abstract": "Thyroid nodule evaluation using ultrasound is dependent on radiologist experience, but deep learning (DL) models can improve intra-reader agreements. DL model development for medical imaging with small datasets can be challenging. Transfer learning is a technique used in the development of DL models to improve model performance in data-limited scenarios. Here, we investigate the impact of transfer learning with domain-specific",
      "num_citations": 0,
      "url": "https://www.sciencedirect.com/science/article/pii/S1546144024005350/pdf?md5=9f8d354ac6921edc5a267290f1a5bcce&pid=1-s2.0-S1546144024005350-main.pdf",
      "article_id": "exploring-the-effect-of-domain-specific--4ebeaff3",
      "bibtex": "@article{erickson2024exploring,\n    author = {Sanaz Vahdati and Bardia Khosravi and Pouria Rouzrokh and Bradley J Erickson},\n    title = {Exploring the Effect of Domain-Specific Transfer Learning for Thyroid Nodule Classification},\n    year = {2024},\n    journal = {Journal of the American College of Radiology},\n    volume = {21},\n    number = {11},\n    pages = {1796-1799},\n    note = {exploring-the-effect-of-domain-specific--4ebeaff3},\n    url = {https://www.sciencedirect.com/science/article/pii/S1546144024005350/pdf?md5=9f8d354ac6921edc5a267290f1a5bcce\\&pid=1-s2.0-S1546144024005350-main.pdf},\n    abstract = {Thyroid nodule evaluation using ultrasound is dependent on radiologist experience, but deep learning (DL) models can improve intra-reader agreements. DL model development for medical imaging with small datasets can be challenging. Transfer learning is a technique used in the development of DL models to improve model performance in data-limited scenarios. Here, we investigate the impact of transfer learning with domain-specific},\n}"
    },
    {
      "title": "Choosing a Career after Radiology Training: Academic, Private Practice, or Industry?",
      "authors": "Jason C Cai, Pouria Rouzrokh, Alfredo P\u00e1ez-Carpio, Thurl Cledera, Felipe C Kitamura",
      "year": 2024,
      "volume": "44",
      "number": "9",
      "pages": "e240050",
      "abstract": "Volume 44 Number 9 2 radiographics. rsna. org extensive training required to be a radiologist is best applied in clinical practice, where these skills are essential and put to their fullest potential. However, this should not be a limiting factor if switching to an industry career aligns with ones interests and ambitions. Moreover, many physicians possess excellent communication skills, adaptability, and grittraits that enable them to flourish in any profession. One should also not be hindered by the lack of additional qualifications, as many skills can be learned in school or on the job. The possibilities for an industry career are vast (10). In recent years, the adoption of artificial intelligence (AI) has also bolstered its appeal and created new opportunities for radiologists. Aside from traditional careers in health care administration, consulting, insurance, and pharmaceutical companies, the radiologists skill set is also valuable in",
      "num_citations": 0,
      "url": "https://pubs.rsna.org/doi/full/10.1148/rg.240050",
      "article_id": "choosing-a-career-after-radiology-traini-8a66eabd",
      "bibtex": "@article{kitamura2024choosing,\n    author = {Jason C Cai and Pouria Rouzrokh and Alfredo P\u00e1ez-Carpio and Thurl Cledera and Felipe C Kitamura},\n    title = {Choosing a Career after Radiology Training: Academic, Private Practice, or Industry?},\n    year = {2024},\n    volume = {44},\n    number = {9},\n    pages = {e240050},\n    note = {choosing-a-career-after-radiology-traini-8a66eabd},\n    url = {https://pubs.rsna.org/doi/full/10.1148/rg.240050},\n    abstract = {Volume 44 Number 9 2 radiographics. rsna. org extensive training required to be a radiologist is best applied in clinical practice, where these skills are essential and put to their fullest potential. However, this should not be a limiting factor if switching to an industry career aligns with ones interests and ambitions. Moreover, many physicians possess excellent communication skills, adaptability, and grittraits that enable them to flourish in any profession. One should also not be hindered by the lack of additional qualifications, as many skills can be learned in school or on the job. The possibilities for an industry career are vast (10). In recent years, the adoption of artificial intelligence (AI) has also bolstered its appeal and created new opportunities for radiologists. Aside from traditional careers in health care administration, consulting, insurance, and pharmaceutical companies, the radiologists skill set is also valuable in},\n}"
    },
    {
      "title": "Ovarian Fibromatosis",
      "authors": "Michael Enea, Parisa Khoshpouri, Augusto Lio da Mota Goncalves Filho, Kaitlin M Zaki-Metias, Pouria Rouzrokh",
      "year": 2024,
      "journal": "RadioGraphics",
      "volume": "44",
      "number": "8",
      "pages": "e240044",
      "abstract": "Doppler images (Fig 2)(2). However, MRI remains the superior modality for comprehensive evaluation, demonstrating T1-and T2-hypointense and T2-dark fibrous components interspersed with normal T2-isointense central ovarian stroma and T2-hyperintense follicles (Fig 3). The characteristic black garland sign refers to the thick peripheral rim of T2 dark signal intensity surrounding the ovaries (Fig 3)(3). Differential diagnoses include ovarian fibrous tumors such as fibromas and fibrothecomas; however, these tumors are diffusely T2 hypointense throughout, while fibromatosis preserves the central ovarian stroma with only the peripheral rind of the ovary demonstrating T2 hypointensity (4).",
      "num_citations": 0,
      "url": "https://pubs.rsna.org/doi/full/10.1148/rg.240044",
      "article_id": "ovarian-fibromatosis-5abb921b",
      "bibtex": "@article{rouzrokh2024ovarian,\n    author = {Michael Enea and Parisa Khoshpouri and Augusto Lio da Mota Goncalves Filho and Kaitlin M Zaki-Metias and Pouria Rouzrokh},\n    title = {Ovarian Fibromatosis},\n    year = {2024},\n    journal = {RadioGraphics},\n    volume = {44},\n    number = {8},\n    pages = {e240044},\n    note = {ovarian-fibromatosis-5abb921b},\n    url = {https://pubs.rsna.org/doi/full/10.1148/rg.240044},\n    abstract = {Doppler images (Fig 2)(2). However, MRI remains the superior modality for comprehensive evaluation, demonstrating T1-and T2-hypointense and T2-dark fibrous components interspersed with normal T2-isointense central ovarian stroma and T2-hyperintense follicles (Fig 3). The characteristic black garland sign refers to the thick peripheral rim of T2 dark signal intensity surrounding the ovaries (Fig 3)(3). Differential diagnoses include ovarian fibrous tumors such as fibromas and fibrothecomas; however, these tumors are diffusely T2 hypointense throughout, while fibromatosis preserves the central ovarian stroma with only the peripheral rind of the ovary demonstrating T2 hypointensity (4).},\n}"
    },
    {
      "title": "RadRotator: 3D Rotation of Radiographs with Diffusion Models",
      "authors": "Pouria Rouzrokh, Bardia Khosravi, Shahriar Faghani, Kellen L Mulford, Michael J Taunton, Bradley J Erickson, Cody C Wyles",
      "year": 2024,
      "journal": "arXiv preprint arXiv:2404.13000",
      "abstract": "Transforming two-dimensional (2D) images into three-dimensional (3D) volumes is a well-known yet challenging problem for the computer vision community. In the medical domain, a few previous studies attempted to convert two or more input radiographs into computed tomography (CT) volumes. Following their effort, we introduce a diffusion model-based technology that can rotate the anatomical content of any input radiograph in 3D space, potentially enabling the visualization of the entire anatomical content of the radiograph from any viewpoint in 3D. Similar to previous studies, we used CT volumes to create Digitally Reconstructed Radiographs (DRRs) as the training data for our model. However, we addressed two significant limitations encountered in previous studies: 1. We utilized conditional diffusion models with classifier-free guidance instead of Generative Adversarial Networks (GANs) to achieve higher mode coverage and improved output image quality, with the only trade-off being slower inference time, which is often less critical in medical applications; and 2. We demonstrated that the unreliable output of style transfer deep learning (DL) models, such as Cycle-GAN, to transfer the style of actual radiographs to DRRs could be replaced with a simple yet effective training transformation that randomly changes the pixel intensity histograms of the input and ground-truth imaging data during training. This transformation makes the diffusion model agnostic to any distribution variations of the input data pixel intensity, enabling the reliable training of a DL model on input DRRs and applying the exact same model to conventional radiographs (or",
      "num_citations": 1,
      "url": "https://arxiv.org/abs/2404.13000",
      "article_id": "radrotator-3d-rotation-of-radiographs-wi-e5612c1a",
      "bibtex": "@article{wyles2024radrotator,\n    author = {Pouria Rouzrokh and Bardia Khosravi and Shahriar Faghani and Kellen L Mulford and Michael J Taunton and Bradley J Erickson and Cody C Wyles},\n    title = {RadRotator: 3D Rotation of Radiographs with Diffusion Models},\n    year = {2024},\n    journal = {arXiv preprint arXiv:2404.13000},\n    note = {radrotator-3d-rotation-of-radiographs-wi-e5612c1a},\n    url = {https://arxiv.org/abs/2404.13000},\n    abstract = {Transforming two-dimensional (2D) images into three-dimensional (3D) volumes is a well-known yet challenging problem for the computer vision community. In the medical domain, a few previous studies attempted to convert two or more input radiographs into computed tomography (CT) volumes. Following their effort, we introduce a diffusion model-based technology that can rotate the anatomical content of any input radiograph in 3D space, potentially enabling the visualization of the entire anatomical content of the radiograph from any viewpoint in 3D. Similar to previous studies, we used CT volumes to create Digitally Reconstructed Radiographs (DRRs) as the training data for our model. However, we addressed two significant limitations encountered in previous studies: 1. We utilized conditional diffusion models with classifier-free guidance instead of Generative Adversarial Networks (GANs) to achieve higher mode coverage and improved output image quality, with the only trade-off being slower inference time, which is often less critical in medical applications; and 2. We demonstrated that the unreliable output of style transfer deep learning (DL) models, such as Cycle-GAN, to transfer the style of actual radiographs to DRRs could be replaced with a simple yet effective training transformation that randomly changes the pixel intensity histograms of the input and ground-truth imaging data during training. This transformation makes the diffusion model agnostic to any distribution variations of the input data pixel intensity, enabling the reliable training of a DL model on input DRRs and applying the exact same model to conventional radiographs (or},\n}"
    },
    {
      "title": "Trainee Research Prizes from the 2023 RSNA Scientific Assembly and Annual Meeting",
      "authors": "Berat Bersu Ozcan, Leyla Zeitouni, Jo\u00e3o Manoel Miranda Magalhaes Santos, Yuki Arita, Pouria Rouzrokh, Cristina Marrocchio, Ashwin Singh Parihar, Kamyar Moradi, Prabhvir S Marway, Ngoc Anh Tran, Burak B Ozkara, Emiliano Garza Frias, Heying Duan, Camilo A Calixto, Mahdie Hosseini, Jeannette R Wong-Siegel, Mangun Randhawa, Yulu Liu, Hau Wai Wong, Anika Walia, Nathan Sarkar, Nika Elmi, Daniel H Kim, Wei Chen, Dallin Judd, Shreyas Kulkarni, Abinaya Ramakrishnan, Tongtong Chen, Vandan Patel, Simone Kaltenhauser, Brittany Q Dang, Daniel Kwon, Alexis M Medema, Huiling Xiang, Joseph Bae, Yang Zhang, Logan Hubbard, Xiaorui Xiang, John Andrew Knopf, Suvrankar Datta, Shankar Kumar, Aditi Chaurasia, Alessandra de Pinho Pimenta Borges, Bryan Quah, Yifan Wang, Bingjie Zheng, Anika Dutta, Alexander Rau, Amar Prasad Gupta, Catherine Meyer, Bailey Lyttle, Vidya Sankar Viswanathan, Dan Bushe, Emily Koons, Joseph Lee, Jim Zhong, Huiming Dong",
      "year": 2024,
      "journal": "Radiology",
      "volume": "310",
      "number": "2",
      "abstract": "Trainee Research Prizes from the 2023 RSNA Scientific Assembly and Annual Meeting - Research Profiles at Washington University School of Medicine Skip to main navigation Skip to search Skip to main content Research Profiles at Washington University School of Medicine Home Research Profiles at Washington University School of Medicine Logo Help FAQ Home Profiles Departments, Divisions and Centers Research output Search by expertise, name or affiliation Trainee Research Prizes from the 2023 RSNA Scientific Assembly and Annual Meeting Berat Bersu Ozcan, Leyla Zeitouni, Jo\u00e3o Manoel Miranda Magalhaes Santos, Yuki Arita, Pouria Rouzrokh, Cristina Marrocchio, Ashwin Singh Parihar, Kamyar Moradi, Prabhvir S. Marway, Ngoc Anh Tran, Burak B. Ozkara, Emiliano Garza Frias, Heying Duan, Camilo A. Calixto, Mahdie Hosseini, Jeannette R. Wong-Siegel, Mangun Randhawa, Yulu Liu, Hau Wai",
      "num_citations": 0,
      "url": "https://profiles.wustl.edu/en/publications/trainee-research-prizes-from-the-2023-rsna-scientific-assembly-an",
      "article_id": "trainee-research-prizes-from-the-2023-rs-4e423695",
      "bibtex": "@article{dong2024trainee,\n    author = {Berat Bersu Ozcan and Leyla Zeitouni and Jo\u00e3o Manoel Miranda Magalhaes Santos and Yuki Arita and Pouria Rouzrokh and Cristina Marrocchio and Ashwin Singh Parihar and Kamyar Moradi and Prabhvir S Marway and Ngoc Anh Tran and Burak B Ozkara and Emiliano Garza Frias and Heying Duan and Camilo A Calixto and Mahdie Hosseini and Jeannette R Wong-Siegel and Mangun Randhawa and Yulu Liu and Hau Wai Wong and Anika Walia and Nathan Sarkar and Nika Elmi and Daniel H Kim and Wei Chen and Dallin Judd and Shreyas Kulkarni and Abinaya Ramakrishnan and Tongtong Chen and Vandan Patel and Simone Kaltenhauser and Brittany Q Dang and Daniel Kwon and Alexis M Medema and Huiling Xiang and Joseph Bae and Yang Zhang and Logan Hubbard and Xiaorui Xiang and John Andrew Knopf and Suvrankar Datta and Shankar Kumar and Aditi Chaurasia and Alessandra de Pinho Pimenta Borges and Bryan Quah and Yifan Wang and Bingjie Zheng and Anika Dutta and Alexander Rau and Amar Prasad Gupta and Catherine Meyer and Bailey Lyttle and Vidya Sankar Viswanathan and Dan Bushe and Emily Koons and Joseph Lee and Jim Zhong and Huiming Dong},\n    title = {Trainee Research Prizes from the 2023 RSNA Scientific Assembly and Annual Meeting},\n    year = {2024},\n    journal = {Radiology},\n    volume = {310},\n    number = {2},\n    note = {trainee-research-prizes-from-the-2023-rs-4e423695},\n    url = {https://profiles.wustl.edu/en/publications/trainee-research-prizes-from-the-2023-rsna-scientific-assembly-an},\n    abstract = {Trainee Research Prizes from the 2023 RSNA Scientific Assembly and Annual Meeting - Research Profiles at Washington University School of Medicine Skip to main navigation Skip to search Skip to main content Research Profiles at Washington University School of Medicine Home Research Profiles at Washington University School of Medicine Logo Help FAQ Home Profiles Departments, Divisions and Centers Research output Search by expertise, name or affiliation Trainee Research Prizes from the 2023 RSNA Scientific Assembly and Annual Meeting Berat Bersu Ozcan, Leyla Zeitouni, Jo\u00e3o Manoel Miranda Magalhaes Santos, Yuki Arita, Pouria Rouzrokh, Cristina Marrocchio, Ashwin Singh Parihar, Kamyar Moradi, Prabhvir S. Marway, Ngoc Anh Tran, Burak B. Ozkara, Emiliano Garza Frias, Heying Duan, Camilo A. Calixto, Mahdie Hosseini, Jeannette R. Wong-Siegel, Mangun Randhawa, Yulu Liu, Hau Wai},\n}"
    },
    {
      "title": "Quantifying uncertainty in deep learning of radiologic images",
      "authors": "Shahriar Faghani, Mana Moassefi, Pouria Rouzrokh, Bardia Khosravi, Francis I Baffour, Michael D Ringler, Bradley J Erickson",
      "year": 2023,
      "volume": "308",
      "number": "2",
      "pages": "e222217",
      "abstract": "In recent years, deep learning (DL) has shown impressive performance in radiologic image analysis. However, for a DL model to be useful in a real-world setting, its confidence in a prediction must also be known. Each DL models output has an estimated probability, and these estimated probabilities are not always reliable. Uncertainty represents the trustworthiness (validity) of estimated probabilities. The higher the uncertainty, the lower the validity. Uncertainty quantification (UQ) methods determine the uncertainty level of each prediction. Predictions made without UQ methods are generally not trustworthy. By implementing UQ in medical DL models, users can be alerted when a model does not have enough information to make a confident decision. Consequently, a medical expert could reevaluate the",
      "num_citations": 63,
      "url": "https://pubs.rsna.org/doi/abs/10.1148/radiol.222217",
      "article_id": "quantifying-uncertainty-in-deep-learning-4db78810",
      "bibtex": "@article{erickson2023quantifying,\n    author = {Shahriar Faghani and Mana Moassefi and Pouria Rouzrokh and Bardia Khosravi and Francis I Baffour and Michael D Ringler and Bradley J Erickson},\n    title = {Quantifying uncertainty in deep learning of radiologic images},\n    year = {2023},\n    volume = {308},\n    number = {2},\n    pages = {e222217},\n    note = {quantifying-uncertainty-in-deep-learning-4db78810},\n    url = {https://pubs.rsna.org/doi/abs/10.1148/radiol.222217},\n    abstract = {In recent years, deep learning (DL) has shown impressive performance in radiologic image analysis. However, for a DL model to be useful in a real-world setting, its confidence in a prediction must also be known. Each DL models output has an estimated probability, and these estimated probabilities are not always reliable. Uncertainty represents the trustworthiness (validity) of estimated probabilities. The higher the uncertainty, the lower the validity. Uncertainty quantification (UQ) methods determine the uncertainty level of each prediction. Predictions made without UQ methods are generally not trustworthy. By implementing UQ in medical DL models, users can be alerted when a model does not have enough information to make a confident decision. Consequently, a medical expert could reevaluate the},\n}"
    },
    {
      "title": "A deep learning algorithm for detecting lytic bone lesions of multiple myeloma on CT",
      "authors": "Shahriar Faghani, Francis I Baffour, Michael D Ringler, Matthew Hamilton-Cave, Pouria Rouzrokh, Mana Moassefi, Bardia Khosravi, Bradley J Erickson",
      "year": 2023,
      "journal": "Skeletal Radiology",
      "volume": "52",
      "number": "1",
      "pages": "91-98",
      "abstract": "Whole-body low-dose CT is the recommended initial imaging modality to evaluate bone destruction as a result of multiple myeloma. Accurate interpretation of these scans to detect small lytic bone lesions is time intensive. A functional deep learning) algorithm to detect lytic lesions on CTs could improve the value of these CTs for myeloma imaging. Our objectives were to develop a DL algorithm and determine its performance at detecting lytic lesions of multiple myeloma.Axial slices (2-mm section thickness) from whole-body low-dose CT scans of subjects with biochemically confirmed plasma cell dyscrasias were included in the study. Data were split into train and test sets at the patient level targeting a 9010 split. Two musculoskeletal radiologists annotated lytic lesions on the images with bounding boxes. Subsequently, we developed a two-step deep learning model comprising bone",
      "num_citations": 29,
      "url": "https://link.springer.com/article/10.1007/s00256-022-04160-z",
      "article_id": "a-deep-learning-algorithm-for-detecting--e65b6643",
      "bibtex": "@article{erickson2023a,\n    author = {Shahriar Faghani and Francis I Baffour and Michael D Ringler and Matthew Hamilton-Cave and Pouria Rouzrokh and Mana Moassefi and Bardia Khosravi and Bradley J Erickson},\n    title = {A deep learning algorithm for detecting lytic bone lesions of multiple myeloma on CT},\n    year = {2023},\n    journal = {Skeletal Radiology},\n    volume = {52},\n    number = {1},\n    pages = {91-98},\n    note = {a-deep-learning-algorithm-for-detecting--e65b6643},\n    url = {https://link.springer.com/article/10.1007/s00256-022-04160-z},\n    abstract = {Whole-body low-dose CT is the recommended initial imaging modality to evaluate bone destruction as a result of multiple myeloma. Accurate interpretation of these scans to detect small lytic bone lesions is time intensive. A functional deep learning) algorithm to detect lytic lesions on CTs could improve the value of these CTs for myeloma imaging. Our objectives were to develop a DL algorithm and determine its performance at detecting lytic lesions of multiple myeloma.Axial slices (2-mm section thickness) from whole-body low-dose CT scans of subjects with biochemically confirmed plasma cell dyscrasias were included in the study. Data were split into train and test sets at the patient level targeting a 9010 split. Two musculoskeletal radiologists annotated lytic lesions on the images with bounding boxes. Subsequently, we developed a two-step deep learning model comprising bone},\n}"
    },
    {
      "title": "Creating high fidelity synthetic pelvis radiographs using generative adversarial networks: unlocking the potential of deep learning models without patient privacy concerns",
      "authors": "Bardia Khosravi, Pouria Rouzrokh, John P Mickley, Shahriar Faghani, A Noelle Larson, Hillary W Garner, Benjamin M Howe, Bradley J Erickson, Michael J Taunton, Cody C Wyles",
      "year": 2023,
      "journal": "The Journal of Arthroplasty",
      "volume": "38",
      "number": "10",
      "pages": "2037-2043. e1",
      "abstract": "In this work, we applied and validated an artificial intelligence technique known as generative adversarial networks (GANs) to create large volumes of high-fidelity synthetic anteroposterior (AP) pelvis radiographs that can enable deep learning (DL)-based image analyses, while ensuring patient privacy.AP pelvis radiographs with native hips were gathered from an institutional registry between 1998 and 2018. The data was used to train a model to create 512 512 pixel synthetic AP pelvis images. The network was trained on 25 million images produced through augmentation. A set of 100 random images (5050 realsynthetic) was evaluated by 3 orthopaedic surgeons and 2 radiologists to discern real versus synthetic images. Two models (joint localization and segmentation) were trained using synthetic images and tested on real images.The final model was trained on 37,640 real",
      "num_citations": 22,
      "url": "https://www.sciencedirect.com/science/article/pii/S0883540322010877",
      "article_id": "creating-high-fidelity-synthetic-pelvis--7ee2f83a",
      "bibtex": "@article{wyles2023creating,\n    author = {Bardia Khosravi and Pouria Rouzrokh and John P Mickley and Shahriar Faghani and A Noelle Larson and Hillary W Garner and Benjamin M Howe and Bradley J Erickson and Michael J Taunton and Cody C Wyles},\n    title = {Creating high fidelity synthetic pelvis radiographs using generative adversarial networks: unlocking the potential of deep learning models without patient privacy concerns},\n    year = {2023},\n    journal = {The Journal of Arthroplasty},\n    volume = {38},\n    number = {10},\n    pages = {2037-2043. e1},\n    note = {creating-high-fidelity-synthetic-pelvis--7ee2f83a},\n    url = {https://www.sciencedirect.com/science/article/pii/S0883540322010877},\n    abstract = {In this work, we applied and validated an artificial intelligence technique known as generative adversarial networks (GANs) to create large volumes of high-fidelity synthetic anteroposterior (AP) pelvis radiographs that can enable deep learning (DL)-based image analyses, while ensuring patient privacy.AP pelvis radiographs with native hips were gathered from an institutional registry between 1998 and 2018. The data was used to train a model to create 512 512 pixel synthetic AP pelvis images. The network was trained on 25 million images produced through augmentation. A set of 100 random images (5050 realsynthetic) was evaluated by 3 orthopaedic surgeons and 2 radiologists to discern real versus synthetic images. Two models (joint localization and segmentation) were trained using synthetic images and tested on real images.The final model was trained on 37,640 real},\n}"
    },
    {
      "title": "Frank stinchfield award: creation of a patient-specific total hip arthroplasty periprosthetic fracture risk calculator",
      "authors": "Cody C Wyles, Hilal Maradit-Kremers, Kristin M Fruth, Dirk R Larson, Bardia Khosravi, Pouria Rouzrokh, Quinn J Johnson, Daniel J Berry, Rafael J Sierra, Michael J Taunton, Matthew P Abdel",
      "year": 2023,
      "journal": "The Journal of arthroplasty",
      "volume": "38",
      "number": "7",
      "pages": "S2-S10",
      "abstract": "Many risk factors have been described for periprosthetic femur fracture (PPFFx) following total hip arthroplasty (THA), yet a patient-specific risk assessment tool remains elusive. The purpose of this study was to develop a high-dimensional, patient-specific risk-stratification nomogram that allows dynamic risk modification based on operative decisions.We evaluated 16,696 primary nononcologic THAs performed between 1998 and 2018. During a mean 6-year follow-up, 558 patients (3.3) sustained a PPFFx. Patients were characterized by individual natural language processing-assisted chart review on nonmodifiable factors (demographics, THA indication, and comorbidities), and modifiable operative decisions (femoral fixation cementeduncemented, surgical approach direct anterior, lateral, and posterior, and implant type collaredcollarless). Multivariable Cox regression models and",
      "num_citations": 18,
      "url": "https://www.sciencedirect.com/science/article/pii/S0883540323002449",
      "article_id": "frank-stinchfield-award-creation-of-a-pa-858fc634",
      "bibtex": "@article{abdel2023frank,\n    author = {Cody C Wyles and Hilal Maradit-Kremers and Kristin M Fruth and Dirk R Larson and Bardia Khosravi and Pouria Rouzrokh and Quinn J Johnson and Daniel J Berry and Rafael J Sierra and Michael J Taunton and Matthew P Abdel},\n    title = {Frank stinchfield award: creation of a patient-specific total hip arthroplasty periprosthetic fracture risk calculator},\n    year = {2023},\n    journal = {The Journal of arthroplasty},\n    volume = {38},\n    number = {7},\n    pages = {S2-S10},\n    note = {frank-stinchfield-award-creation-of-a-pa-858fc634},\n    url = {https://www.sciencedirect.com/science/article/pii/S0883540323002449},\n    abstract = {Many risk factors have been described for periprosthetic femur fracture (PPFFx) following total hip arthroplasty (THA), yet a patient-specific risk assessment tool remains elusive. The purpose of this study was to develop a high-dimensional, patient-specific risk-stratification nomogram that allows dynamic risk modification based on operative decisions.We evaluated 16,696 primary nononcologic THAs performed between 1998 and 2018. During a mean 6-year follow-up, 558 patients (3.3) sustained a PPFFx. Patients were characterized by individual natural language processing-assisted chart review on nonmodifiable factors (demographics, THA indication, and comorbidities), and modifiable operative decisions (femoral fixation cementeduncemented, surgical approach direct anterior, lateral, and posterior, and implant type collaredcollarless). Multivariable Cox regression models and},\n}"
    },
    {
      "title": "Reproducibility of deep learning algorithms developed for medical imaging analysis: A systematic review",
      "authors": "Mana Moassefi, Pouria Rouzrokh, Gian Marco Conte, Sanaz Vahdati, Tianyuan Fu, Aylin Tahmasebi, Mira Younis, Keyvan Farahani, Amilcare Gentili, Timothy Kline, Felipe C Kitamura, Yuankai Huo, Shiba Kuanar, Khaled Younis, Bradley J Erickson, Shahriar Faghani",
      "year": 2023,
      "volume": "36",
      "number": "5",
      "pages": "2306-2312",
      "abstract": "Since 2000, there have been more than 8000 publications on radiology artificial intelligence (AI). AI breakthroughs allow complex tasks to be automated and even performed beyond human capabilities. However, the lack of details on the methods and algorithm code undercuts its scientific value. Many science subfields have recently faced a reproducibility crisis, eroding trust in processes and results, and influencing the rise in retractions of scientific papers. For the same reasons, conducting research in deep learning (DL) also requires reproducibility. Although several valuable manuscript checklists for AI in medical imaging exist, they are not focused specifically on reproducibility. In this study, we conducted a systematic review of recently published papers in the field of DL to evaluate if the description of their methodology could allow the reproducibility of their findings. We focused on the Journal of Digital Imaging",
      "num_citations": 16,
      "url": "https://link.springer.com/article/10.1007/s10278-023-00870-5",
      "article_id": "reproducibility-of-deep-learning-algorit-61a75952",
      "bibtex": "@article{faghani2023reproducibility,\n    author = {Mana Moassefi and Pouria Rouzrokh and Gian Marco Conte and Sanaz Vahdati and Tianyuan Fu and Aylin Tahmasebi and Mira Younis and Keyvan Farahani and Amilcare Gentili and Timothy Kline and Felipe C Kitamura and Yuankai Huo and Shiba Kuanar and Khaled Younis and Bradley J Erickson and Shahriar Faghani},\n    title = {Reproducibility of deep learning algorithms developed for medical imaging analysis: A systematic review},\n    year = {2023},\n    volume = {36},\n    number = {5},\n    pages = {2306-2312},\n    note = {reproducibility-of-deep-learning-algorit-61a75952},\n    url = {https://link.springer.com/article/10.1007/s10278-023-00870-5},\n    abstract = {Since 2000, there have been more than 8000 publications on radiology artificial intelligence (AI). AI breakthroughs allow complex tasks to be automated and even performed beyond human capabilities. However, the lack of details on the methods and algorithm code undercuts its scientific value. Many science subfields have recently faced a reproducibility crisis, eroding trust in processes and results, and influencing the rise in retractions of scientific papers. For the same reasons, conducting research in deep learning (DL) also requires reproducibility. Although several valuable manuscript checklists for AI in medical imaging exist, they are not focused specifically on reproducibility. In this study, we conducted a systematic review of recently published papers in the field of DL to evaluate if the description of their methodology could allow the reproducibility of their findings. We focused on the Journal of Digital Imaging},\n}"
    },
    {
      "title": "Developing and validating a national set of standards for undergraduate medical education using the WFME framework: the experience of an accreditation system in Iran",
      "authors": "Roghayeh Gandomkar, Tahereh Changiz, Athar Omid, Mahasti Alizadeh, Majid Khazaei, Abtin Heidarzadah, Pouria Rouzrokh, Mitra Amini, Hamid Honarpisheh, Reza Laripour, Farshid Abedi, Babak Sabet, Azim Mirzazadeh",
      "year": 2023,
      "journal": "BMC Medical Education",
      "volume": "23",
      "number": "1",
      "pages": "379",
      "abstract": "Defining standards is the first step toward quality assurance and improvement of educational programs. This study aimed at developing and validating a set of national standards for the Undergraduate Medical Education (UME) program through an accreditation system in Iran using the World Federation for Medical Education (WFME) framework.The first draft of standards was prepared through consultative workshops with the participation of different UME program stakeholders. Subsequently, standards were sent to medical schools and UME directors were asked to complete a web-based survey. The content validity index at the item level (I-CVI) was computed using criteria including clarity, relevance, optimization and evaluability for each standard. Afterward, a full-day consultative workshop was held and a wide range of UME stakeholders across the country (n 150) discussed the survey",
      "num_citations": 18,
      "url": "https://link.springer.com/article/10.1186/s12909-023-04343-9",
      "article_id": "developing-and-validating-a-national-set-b3dbaa1f",
      "bibtex": "@article{mirzazadeh2023developing,\n    author = {Roghayeh Gandomkar and Tahereh Changiz and Athar Omid and Mahasti Alizadeh and Majid Khazaei and Abtin Heidarzadah and Pouria Rouzrokh and Mitra Amini and Hamid Honarpisheh and Reza Laripour and Farshid Abedi and Babak Sabet and Azim Mirzazadeh},\n    title = {Developing and validating a national set of standards for undergraduate medical education using the WFME framework: the experience of an accreditation system in Iran},\n    year = {2023},\n    journal = {BMC Medical Education},\n    volume = {23},\n    number = {1},\n    pages = {379},\n    note = {developing-and-validating-a-national-set-b3dbaa1f},\n    url = {https://link.springer.com/article/10.1186/s12909-023-04343-9},\n    abstract = {Defining standards is the first step toward quality assurance and improvement of educational programs. This study aimed at developing and validating a set of national standards for the Undergraduate Medical Education (UME) program through an accreditation system in Iran using the World Federation for Medical Education (WFME) framework.The first draft of standards was prepared through consultative workshops with the participation of different UME program stakeholders. Subsequently, standards were sent to medical schools and UME directors were asked to complete a web-based survey. The content validity index at the item level (I-CVI) was computed using criteria including clarity, relevance, optimization and evaluability for each standard. Afterward, a full-day consultative workshop was held and a wide range of UME stakeholders across the country (n 150) discussed the survey},\n}"
    },
    {
      "title": "A deep learning tool for automated landmark annotation on hip and pelvis radiographs",
      "authors": "Kellen L Mulford, Quinn J Johnson, Tala Mujahed, Bardia Khosravi, Pouria Rouzrokh, John P Mickley, Michael J Taunton, Cody C Wyles",
      "year": 2023,
      "journal": "The Journal of Arthroplasty",
      "volume": "38",
      "number": "10",
      "pages": "2024-2031. e1",
      "abstract": "BackgroundAutomatic methods for labeling and segmenting pelvis structures can improve the efficiency of clinical and research workflows and reduce the variability introduced with manual labeling. The purpose of this study was to develop a single deep learning model to annotate certain anatomical structures and landmarks on antero-posterior (AP) pelvis radiographs.MethodsA total of 1,100 AP pelvis radiographs were manually annotated by 3 reviewers. These images included a mix of preoperative and postoperative images as well as a mix of AP pelvis and hip images. A convolutional neural network was trained to segment 22 different structures (7 points, 6 lines, and 9 shapes). Dice score, which measures overlap between model output and ground truth, was calculated for the shapes and lines structures. Euclidean distance error was calculated for point structures.ResultsDice score averaged across all",
      "num_citations": 12,
      "url": "https://www.sciencedirect.com/science/article/pii/S0883540323005600",
      "article_id": "a-deep-learning-tool-for-automated-landm-bac51253",
      "bibtex": "@article{wyles2023a,\n    author = {Kellen L Mulford and Quinn J Johnson and Tala Mujahed and Bardia Khosravi and Pouria Rouzrokh and John P Mickley and Michael J Taunton and Cody C Wyles},\n    title = {A deep learning tool for automated landmark annotation on hip and pelvis radiographs},\n    year = {2023},\n    journal = {The Journal of Arthroplasty},\n    volume = {38},\n    number = {10},\n    pages = {2024-2031. e1},\n    note = {a-deep-learning-tool-for-automated-landm-bac51253},\n    url = {https://www.sciencedirect.com/science/article/pii/S0883540323005600},\n    abstract = {BackgroundAutomatic methods for labeling and segmenting pelvis structures can improve the efficiency of clinical and research workflows and reduce the variability introduced with manual labeling. The purpose of this study was to develop a single deep learning model to annotate certain anatomical structures and landmarks on antero-posterior (AP) pelvis radiographs.MethodsA total of 1,100 AP pelvis radiographs were manually annotated by 3 reviewers. These images included a mix of preoperative and postoperative images as well as a mix of AP pelvis and hip images. A convolutional neural network was trained to segment 22 different structures (7 points, 6 lines, and 9 shapes). Dice score, which measures overlap between model output and ground truth, was calculated for the shapes and lines structures. Euclidean distance error was calculated for point structures.ResultsDice score averaged across all},\n}"
    },
    {
      "title": "Few-shot biomedical image segmentation using diffusion models: beyond image generation",
      "authors": "Bardia Khosravi, Pouria Rouzrokh, John P Mickley, Shahriar Faghani, Kellen Mulford, Linjun Yang, A Noelle Larson, Benjamin M Howe, Bradley J Erickson, Michael J Taunton, Cody C Wyles",
      "year": 2023,
      "journal": "Computer Methods and Programs in Biomedicine",
      "volume": "242",
      "pages": "107832",
      "abstract": "BackgroundMedical image analysis pipelines often involve segmentation, which requires a large amount of annotated training data, which is time-consuming and costly. To address this issue, we proposed leveraging generative models to achieve few-shot image segmentation.MethodsWe trained a denoising diffusion probabilistic model (DDPM) on 480,407 pelvis radiographs to generate 256 256 px synthetic images. The DDPM was conditioned on demographic and radiologic characteristics and was rigorously validated by domain experts and objective image quality metrics (Frechet inception distance FID and inception score IS). For the next step, three landmarks (greater trochanter GT, lesser trochanter LT, and obturator foramen OF) were annotated on 45 real-patient radiographs; 25 for training and 20 for testing. To extract features, each image was passed through the pre-trained DDPM at three",
      "num_citations": 12,
      "url": "https://www.sciencedirect.com/science/article/pii/S0169260723004984",
      "article_id": "few-shot-biomedical-image-segmentation-u-88d11feb",
      "bibtex": "@article{wyles2023fewshot,\n    author = {Bardia Khosravi and Pouria Rouzrokh and John P Mickley and Shahriar Faghani and Kellen Mulford and Linjun Yang and A Noelle Larson and Benjamin M Howe and Bradley J Erickson and Michael J Taunton and Cody C Wyles},\n    title = {Few-shot biomedical image segmentation using diffusion models: beyond image generation},\n    year = {2023},\n    journal = {Computer Methods and Programs in Biomedicine},\n    volume = {242},\n    pages = {107832},\n    note = {few-shot-biomedical-image-segmentation-u-88d11feb},\n    url = {https://www.sciencedirect.com/science/article/pii/S0169260723004984},\n    abstract = {BackgroundMedical image analysis pipelines often involve segmentation, which requires a large amount of annotated training data, which is time-consuming and costly. To address this issue, we proposed leveraging generative models to achieve few-shot image segmentation.MethodsWe trained a denoising diffusion probabilistic model (DDPM) on 480,407 pelvis radiographs to generate 256 256 px synthetic images. The DDPM was conditioned on demographic and radiologic characteristics and was rigorously validated by domain experts and objective image quality metrics (Frechet inception distance FID and inception score IS). For the next step, three landmarks (greater trochanter GT, lesser trochanter LT, and obturator foramen OF) were annotated on 45 real-patient radiographs; 25 for training and 20 for testing. To extract features, each image was passed through the pre-trained DDPM at three},\n}"
    },
    {
      "title": "Anonymizing radiographs using an object detection deep learning algorithm",
      "authors": "Bardia Khosravi, John P Mickley, Pouria Rouzrokh, Michael J Taunton, A Noelle Larson, Bradley J Erickson, Cody C Wyles",
      "year": 2023,
      "journal": "Radiology: Artificial Intelligence",
      "volume": "5",
      "number": "6",
      "pages": "e230085",
      "abstract": "Radiographic markers contain protected health information that must be removed before public release. This work presents a deep learning algorithm that localizes radiographic markers and selectively removes them to enable de-identified data sharing. The authors annotated 2000 hip and pelvic radiographs to train an object detection computer vision model. Data were split into training, validation, and test sets at the patient level. Extracted markers were then characterized using an image processing algorithm, and potentially useful markers (eg, L and R) without identifying information were retained. The model achieved an area under the precision-recall curve of 0.96 on the internal test set. The de-identification accuracy was 100 (400 of 400), with a de-identification false-positive rate of 1 (eight of",
      "num_citations": 11,
      "url": "https://pubs.rsna.org/doi/abs/10.1148/ryai.230085",
      "article_id": "anonymizing-radiographs-using-an-object--50d49211",
      "bibtex": "@article{wyles2023anonymizing,\n    author = {Bardia Khosravi and John P Mickley and Pouria Rouzrokh and Michael J Taunton and A Noelle Larson and Bradley J Erickson and Cody C Wyles},\n    title = {Anonymizing radiographs using an object detection deep learning algorithm},\n    year = {2023},\n    journal = {Radiology: Artificial Intelligence},\n    volume = {5},\n    number = {6},\n    pages = {e230085},\n    note = {anonymizing-radiographs-using-an-object--50d49211},\n    url = {https://pubs.rsna.org/doi/abs/10.1148/ryai.230085},\n    abstract = {Radiographic markers contain protected health information that must be removed before public release. This work presents a deep learning algorithm that localizes radiographic markers and selectively removes them to enable de-identified data sharing. The authors annotated 2000 hip and pelvic radiographs to train an object detection computer vision model. Data were split into training, validation, and test sets at the patient level. Extracted markers were then characterized using an image processing algorithm, and potentially useful markers (eg, L and R) without identifying information were retained. The model achieved an area under the precision-recall curve of 0.96 on the internal test set. The de-identification accuracy was 100 (400 of 400), with a de-identification false-positive rate of 1 (eight of},\n}"
    },
    {
      "title": "The use of deep learning in medical imaging to improve spine care: a scoping review of current literature and clinical applications",
      "authors": "Caroline Constant, Carl-Eric Aubin, Hilal Maradit Kremers, Diana V Vera Garcia, Cody C Wyles, Pouria Rouzrokh, Annalise Noelle Larson",
      "year": 2023,
      "volume": "15",
      "pages": "100236",
      "abstract": "Artificial intelligence is a revolutionary technology that promises to assist clinicians in improving patient care. In radiology, deep learning (DL) is widely used in clinical decision aids due to its ability to analyze complex patterns and images. It allows for rapid, enhanced data, and imaging analysis, from diagnosis to outcome prediction. The purpose of this study was to evaluate the current literature and clinical utilization of DL in spine imaging.This study is a scoping review and utilized the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) methodology to review the scientific literature from 2012 to 2021. A search in PubMed, Web of Science, Embased, and IEEE Xplore databases with syntax specific for DL and medical imaging in spine care applications was conducted to collect all original publications on the subject. Specific data was extracted from the available",
      "num_citations": 14,
      "url": "https://www.sciencedirect.com/science/article/pii/S2666548423000380",
      "article_id": "the-use-of-deep-learning-in-medical-imag-4953c71c",
      "bibtex": "@article{larson2023the,\n    author = {Caroline Constant and Carl-Eric Aubin and Hilal Maradit Kremers and Diana V Vera Garcia and Cody C Wyles and Pouria Rouzrokh and Annalise Noelle Larson},\n    title = {The use of deep learning in medical imaging to improve spine care: a scoping review of current literature and clinical applications},\n    year = {2023},\n    volume = {15},\n    pages = {100236},\n    note = {the-use-of-deep-learning-in-medical-imag-4953c71c},\n    url = {https://www.sciencedirect.com/science/article/pii/S2666548423000380},\n    abstract = {Artificial intelligence is a revolutionary technology that promises to assist clinicians in improving patient care. In radiology, deep learning (DL) is widely used in clinical decision aids due to its ability to analyze complex patterns and images. It allows for rapid, enhanced data, and imaging analysis, from diagnosis to outcome prediction. The purpose of this study was to evaluate the current literature and clinical utilization of DL in spine imaging.This study is a scoping review and utilized the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) methodology to review the scientific literature from 2012 to 2021. A search in PubMed, Web of Science, Embased, and IEEE Xplore databases with syntax specific for DL and medical imaging in spine care applications was conducted to collect all original publications on the subject. Specific data was extracted from the available},\n}"
    },
    {
      "title": "Artificial Intelligence in Radiology: Overview of Application Types, Design, and Challenges.",
      "authors": "Mana Moassefi, Shahriar Faghani, Bardia Khosravi, Pouria Rouzrokh, Bradley J Erickson",
      "year": 2023,
      "volume": "58",
      "number": "2",
      "pages": "170-177",
      "abstract": "Artificial Intelligence in Radiology: Overview of Application Types, Design, and Challenges. - Abstract - Europe PMC Sign in Create an account https:orcid.org Europe PMC Menu About Tools Developers Help Contact us Helpdesk Feedback Twitter Blog Tech blog Developer Forum Europe PMC plus Search life-sciences literature (42,181,723 articles, preprints and more) Search Advanced search Feedback This website requires cookies, and the limited processing of your personal data in order to function. By using the site you are agreeing to this as outlined in our privacy notice and cookie policy. Abstract Full text Citations impact Artificial Intelligence in Radiology: Overview of Application Types, Design, and Challenges. Moassefi M 1 , Faghani S 1 , Khosravi B 2 , Rouzrokh P 2 , Erickson BJ 1 Author information Affiliations 3 authors 1. Radiology Informatics Lab (RIL), Department of Radiology, Mayo Clinic,",
      "num_citations": 11,
      "url": "https://europepmc.org/article/med/37087137",
      "article_id": "artificial-intelligence-in-radiology-ove-e6009a89",
      "bibtex": "@article{erickson2023artificial,\n    author = {Mana Moassefi and Shahriar Faghani and Bardia Khosravi and Pouria Rouzrokh and Bradley J Erickson},\n    title = {Artificial Intelligence in Radiology: Overview of Application Types, Design, and Challenges.},\n    year = {2023},\n    volume = {58},\n    number = {2},\n    pages = {170-177},\n    note = {artificial-intelligence-in-radiology-ove-e6009a89},\n    url = {https://europepmc.org/article/med/37087137},\n    abstract = {Artificial Intelligence in Radiology: Overview of Application Types, Design, and Challenges. - Abstract - Europe PMC Sign in Create an account https:orcid.org Europe PMC Menu About Tools Developers Help Contact us Helpdesk Feedback Twitter Blog Tech blog Developer Forum Europe PMC plus Search life-sciences literature (42,181,723 articles, preprints and more) Search Advanced search Feedback This website requires cookies, and the limited processing of your personal data in order to function. By using the site you are agreeing to this as outlined in our privacy notice and cookie policy. Abstract Full text Citations impact Artificial Intelligence in Radiology: Overview of Application Types, Design, and Challenges. Moassefi M 1 , Faghani S 1 , Khosravi B 2 , Rouzrokh P 2 , Erickson BJ 1 Author information Affiliations 3 authors 1. Radiology Informatics Lab (RIL), Department of Radiology, Mayo Clinic,},\n}"
    },
    {
      "title": "Deep learning artificial intelligence tool for automated radiographic determination of posterior tibial slope in patients with ACL injury",
      "authors": "Yining Lu, Ayoosh Pareek, Linjun Yang, Pouria Rouzrokh, Bardia Khosravi, Kelechi R Okoroha, Aaron J Krych, Christopher L Camp",
      "year": 2023,
      "journal": "Orthopaedic journal of sports medicine",
      "volume": "11",
      "number": "12",
      "pages": "23259671231215820",
      "abstract": "An increased posterior tibial slope (PTS) corresponds with an increased risk of graft failure after anterior cruciate ligament (ACL) reconstruction (ACLR). Validated methods of manual PTS measurements are subject to potential interobserver variability and can be inefficient on large datasets.To develop a deep learning artificial intelligence technique for automated PTS measurement from standard lateral knee radiographs. It was hypothesized that this deep learning tool would be able to measure the PTS on a high volume of radiographs expeditiously and that these measurements would be similar to previously validated manual measurements.Cohort study (diagnosis); Level of evidence, 2.A deep learning U-Net model was developed on a cohort of 300 postoperative short-leg lateral radiographs from patients who underwent ACLR to segment the tibial shaft",
      "num_citations": 11,
      "url": "https://journals.sagepub.com/doi/abs/10.1177/23259671231215820",
      "article_id": "deep-learning-artificial-intelligence-to-d10785bf",
      "bibtex": "@article{camp2023deep,\n    author = {Yining Lu and Ayoosh Pareek and Linjun Yang and Pouria Rouzrokh and Bardia Khosravi and Kelechi R Okoroha and Aaron J Krych and Christopher L Camp},\n    title = {Deep learning artificial intelligence tool for automated radiographic determination of posterior tibial slope in patients with ACL injury},\n    year = {2023},\n    journal = {Orthopaedic journal of sports medicine},\n    volume = {11},\n    number = {12},\n    pages = {23259671231215820},\n    note = {deep-learning-artificial-intelligence-to-d10785bf},\n    url = {https://journals.sagepub.com/doi/abs/10.1177/23259671231215820},\n    abstract = {An increased posterior tibial slope (PTS) corresponds with an increased risk of graft failure after anterior cruciate ligament (ACL) reconstruction (ACLR). Validated methods of manual PTS measurements are subject to potential interobserver variability and can be inefficient on large datasets.To develop a deep learning artificial intelligence technique for automated PTS measurement from standard lateral knee radiographs. It was hypothesized that this deep learning tool would be able to measure the PTS on a high volume of radiographs expeditiously and that these measurements would be similar to previously validated manual measurements.Cohort study (diagnosis); Level of evidence, 2.A deep learning U-Net model was developed on a cohort of 300 postoperative short-leg lateral radiographs from patients who underwent ACLR to segment the tibial shaft},\n}"
    },
    {
      "title": "Machine learning in cardiovascular imaging: a scoping review of published literature",
      "authors": "Pouria Rouzrokh, Bardia Khosravi, Sanaz Vahdati, Mana Moassefi, Shahriar Faghani, Elham Mahmoudi, Hamid Chalian, Bradley J Erickson",
      "year": 2023,
      "volume": "11",
      "number": "2",
      "pages": "34-45",
      "abstract": "In this study, we planned and carried out a scoping review of the literature to learn how machine learning (ML) has been investigated in cardiovascular imaging (CVI).During our search, we found numerous studies that developed or utilized existing ML models for segmentation, classification, object detection, generation, and regression applications involving cardiovascular imaging data. We first quantitatively investigated the different aspects of study characteristics, data handling, model development, and performance evaluation in all studies that were included in our review. We then supplemented these findings with a qualitative synthesis to highlight the common themes in the studied literature and provided recommendations to pave the way for upcoming research.ML is a subfield of artificial intelligence (AI) that enables computers to learn human-like decision-making",
      "num_citations": 8,
      "url": "https://link.springer.com/article/10.1007/s40134-022-00407-8",
      "article_id": "machine-learning-in-cardiovascular-imagi-0e059aaa",
      "bibtex": "@article{erickson2023machine,\n    author = {Pouria Rouzrokh and Bardia Khosravi and Sanaz Vahdati and Mana Moassefi and Shahriar Faghani and Elham Mahmoudi and Hamid Chalian and Bradley J Erickson},\n    title = {Machine learning in cardiovascular imaging: a scoping review of published literature},\n    year = {2023},\n    volume = {11},\n    number = {2},\n    pages = {34-45},\n    note = {machine-learning-in-cardiovascular-imagi-0e059aaa},\n    url = {https://link.springer.com/article/10.1007/s40134-022-00407-8},\n    abstract = {In this study, we planned and carried out a scoping review of the literature to learn how machine learning (ML) has been investigated in cardiovascular imaging (CVI).During our search, we found numerous studies that developed or utilized existing ML models for segmentation, classification, object detection, generation, and regression applications involving cardiovascular imaging data. We first quantitatively investigated the different aspects of study characteristics, data handling, model development, and performance evaluation in all studies that were included in our review. We then supplemented these findings with a qualitative synthesis to highlight the common themes in the studied literature and provided recommendations to pave the way for upcoming research.ML is a subfield of artificial intelligence (AI) that enables computers to learn human-like decision-making},\n}"
    },
    {
      "title": "Diagnostic Value of Shear Wave Elastography in Differentiation between Benign from Malignant Cervical Lymph Nodes",
      "authors": "Mohammadreza Chavoshi, Milad Taghavi, Hassan Hashemi, Mohammad Davoodi, Pouria Rouzrokh, Leila Aghaghazvini",
      "year": 2023,
      "journal": "Journal of Iranian Medical Council",
      "abstract": "Background: This study aims to evaluate the role of Shear Wave Elastography (SWE) in the differentiation of malignant from benign cervical lymph nodes and compare its accuracy with conventional ultrasound.Methods: Seventy-one lymph nodes (malignant 52, benign 19) were investigated by both conventional sonography and SWE. Shear Wave Velocity (SWV) and color map were obtained for each lymph node before tissue sampling. R statistical software (x64, v3. 6.1) was used for statistical analysis.Results: Among all the conventional and elastography features, color map grading and shear wave velocity (SWV) had the most correlation with malignancy, even in normal-sized nodes. SWV was significantly correlated with the pathology (rpb 0.62, p 0.00). The best cutoff-value for SWV was 2.71 ms (sensitivity: 82.7, specificity: 84.2, AUC 0.92). The best predicting model by multivariate analysis was obtained by a combination of SWV and color map grading (sensitivity 92.3, specificity 94.7).Conclusion: SWE is a valuable method for the differentiation of malignant from benign lymph nodes. It would help to find the proper lymph node for biopsy.",
      "num_citations": 0,
      "url": "https://publish.kne-publishing.com/index.php/JIMC/article/view/13446",
      "article_id": "diagnostic-value-of-shear-wave-elastogra-5148e899",
      "bibtex": "@article{aghaghazvini2023diagnostic,\n    author = {Mohammadreza Chavoshi and Milad Taghavi and Hassan Hashemi and Mohammad Davoodi and Pouria Rouzrokh and Leila Aghaghazvini},\n    title = {Diagnostic Value of Shear Wave Elastography in Differentiation between Benign from Malignant Cervical Lymph Nodes},\n    year = {2023},\n    journal = {Journal of Iranian Medical Council},\n    note = {diagnostic-value-of-shear-wave-elastogra-5148e899},\n    url = {https://publish.kne-publishing.com/index.php/JIMC/article/view/13446},\n    abstract = {Background: This study aims to evaluate the role of Shear Wave Elastography (SWE) in the differentiation of malignant from benign cervical lymph nodes and compare its accuracy with conventional ultrasound.Methods: Seventy-one lymph nodes (malignant 52, benign 19) were investigated by both conventional sonography and SWE. Shear Wave Velocity (SWV) and color map were obtained for each lymph node before tissue sampling. R statistical software (x64, v3. 6.1) was used for statistical analysis.Results: Among all the conventional and elastography features, color map grading and shear wave velocity (SWV) had the most correlation with malignancy, even in normal-sized nodes. SWV was significantly correlated with the pathology (rpb 0.62, p 0.00). The best cutoff-value for SWV was 2.71 ms (sensitivity: 82.7, specificity: 84.2, AUC 0.92). The best predicting model by multivariate analysis was obtained by a combination of SWV and color map grading (sensitivity 92.3, specificity 94.7).Conclusion: SWE is a valuable method for the differentiation of malignant from benign lymph nodes. It would help to find the proper lymph node for biopsy.},\n}"
    },
    {
      "title": "224 EXTERNAL VALIDATION OF A DEEP LEARNING MODEL FOR WHOLE SLIDE IMAGE ANALYSIS IN THE HISTOLOGIC DIAGNOSIS OF DYSPLASTIC BARRETT'S ESOPHAGUS",
      "authors": "Don C Codipilly, Shahriar Faghani, Karan Sachdeva, Erin Gibbons, Ramona Lansing, Melissa Passe, Cadman L Leggett, David A Katzka, Mana Moassefi, Pouria Rouzrokh, Bardia Khosravi, Catherine E Hagen, Jason T Lewis, Pallavi A Patil, Vani Konda, Shajan Peter, Sameer Al Diffalha, Brian Brinkerhoff, Mary Wong, Fouad Otaki, Nicholas J Shaheen, Bradley Erickson, Prasad G Iyer",
      "year": 2023,
      "journal": "Gastroenterology",
      "volume": "164",
      "number": "6",
      "pages": "S-41",
      "abstract": "223 IMMUNE CELL PHENOTYPING IN BARRETT'S ESOPHAGUS IN PATIENTS PRIOR AND AT TIME OF PROGRESSION Meng-Lay Lin, John W. Hickey, Christian M. Sch\u00c3\u00bcrch, Adam M. Passman, Emanuela Carlotti, Shruthi Devkumar, Richard J. Hackett, Manuel Rodriguez-Justo, Marco Novelli, Marnix Jansen, Philippe D. Gascard, Thea D. Tlsty, Stuart A. McDonald Introduction: Barrett\u00e2 s Esophagus (BE) is characterised by the metaplastic replacement of squamous with columnar epithelium. However, BE is also an inflammatory condition and immune infiltration has been widely reported, little is known about the overall immune landscape at the cellular level, nor do we know much about the genes expressed. Furthermore, the role that immune cells play in progression to cancer is poorly understood. Here we use multiplex immunohistochemistry combined with laser-capture microdissection (LCM) X: 30083",
      "num_citations": 0,
      "url": "https://scholar.google.com/scholar?cluster=15554211358975102762&hl=en&oi=scholarr",
      "article_id": "224-external-validation-of-a-deep-learni-7951e048",
      "bibtex": "@article{iyer2023224,\n    author = {Don C Codipilly and Shahriar Faghani and Karan Sachdeva and Erin Gibbons and Ramona Lansing and Melissa Passe and Cadman L Leggett and David A Katzka and Mana Moassefi and Pouria Rouzrokh and Bardia Khosravi and Catherine E Hagen and Jason T Lewis and Pallavi A Patil and Vani Konda and Shajan Peter and Sameer Al Diffalha and Brian Brinkerhoff and Mary Wong and Fouad Otaki and Nicholas J Shaheen and Bradley Erickson and Prasad G Iyer},\n    title = {224 EXTERNAL VALIDATION OF A DEEP LEARNING MODEL FOR WHOLE SLIDE IMAGE ANALYSIS IN THE HISTOLOGIC DIAGNOSIS OF DYSPLASTIC BARRETT'S ESOPHAGUS},\n    year = {2023},\n    journal = {Gastroenterology},\n    volume = {164},\n    number = {6},\n    pages = {S-41},\n    note = {224-external-validation-of-a-deep-learni-7951e048},\n    url = {https://scholar.google.com/scholar?cluster=15554211358975102762\\&hl=en\\&oi=scholarr},\n    abstract = {223 IMMUNE CELL PHENOTYPING IN BARRETT'S ESOPHAGUS IN PATIENTS PRIOR AND AT TIME OF PROGRESSION Meng-Lay Lin, John W. Hickey, Christian M. Sch\u00c3\u00bcrch, Adam M. Passman, Emanuela Carlotti, Shruthi Devkumar, Richard J. Hackett, Manuel Rodriguez-Justo, Marco Novelli, Marnix Jansen, Philippe D. Gascard, Thea D. Tlsty, Stuart A. McDonald Introduction: Barrett\u00e2 s Esophagus (BE) is characterised by the metaplastic replacement of squamous with columnar epithelium. However, BE is also an inflammatory condition and immune infiltration has been widely reported, little is known about the overall immune landscape at the cellular level, nor do we know much about the genes expressed. Furthermore, the role that immune cells play in progression to cancer is poorly understood. Here we use multiplex immunohistochemistry combined with laser-capture microdissection (LCM) X: 30083},\n}"
    },
    {
      "title": "Mitigating bias in radiology machine learning: 1. Data handling",
      "authors": "Pouria Rouzrokh, Bardia Khosravi, Shahriar Faghani, Mana Moassefi, Diana V Vera Garcia, Yashbir Singh, Kuan Zhang, Gian Marco Conte, Bradley J Erickson",
      "year": 2022,
      "journal": "Radiology: Artificial Intelligence",
      "volume": "4",
      "number": "5",
      "pages": "e210290",
      "abstract": "Minimizing bias is critical to adoption and implementation of machine learning (ML) in clinical practice. Systematic mathematical biases produce consistent and reproducible differences between the observed and expected performance of ML systems, resulting in suboptimal performance. Such biases can be traced back to various phases of ML development: data handling, model development, and performance evaluation. This report presents 12 suboptimal practices during data handling of an ML study, explains how those practices can lead to biases, and describes what may be done to mitigate them. Authors employ an arbitrary and simplified framework that splits ML data handling into four steps: data collection, data investigation, data splitting, and feature engineering. Examples from the available",
      "num_citations": 124,
      "url": "https://pubs.rsna.org/doi/abs/10.1148/ryai.210290",
      "article_id": "mitigating-bias-in-radiology-machine-lea-0aea1c69",
      "bibtex": "@article{erickson2022mitigating,\n    author = {Pouria Rouzrokh and Bardia Khosravi and Shahriar Faghani and Mana Moassefi and Diana V Vera Garcia and Yashbir Singh and Kuan Zhang and Gian Marco Conte and Bradley J Erickson},\n    title = {Mitigating bias in radiology machine learning: 1. Data handling},\n    year = {2022},\n    journal = {Radiology: Artificial Intelligence},\n    volume = {4},\n    number = {5},\n    pages = {e210290},\n    note = {mitigating-bias-in-radiology-machine-lea-0aea1c69},\n    url = {https://pubs.rsna.org/doi/abs/10.1148/ryai.210290},\n    abstract = {Minimizing bias is critical to adoption and implementation of machine learning (ML) in clinical practice. Systematic mathematical biases produce consistent and reproducible differences between the observed and expected performance of ML systems, resulting in suboptimal performance. Such biases can be traced back to various phases of ML development: data handling, model development, and performance evaluation. This report presents 12 suboptimal practices during data handling of an ML study, explains how those practices can lead to biases, and describes what may be done to mitigate them. Authors employ an arbitrary and simplified framework that splits ML data handling into four steps: data collection, data investigation, data splitting, and feature engineering. Examples from the available},\n}"
    },
    {
      "title": "SOUP-GAN: Super-resolution MRI using generative adversarial networks",
      "authors": "Kuan Zhang, Haoji Hu, Kenneth Philbrick, Gian Marco Conte, Joseph D Sobek, Pouria Rouzrokh, Bradley J Erickson",
      "year": 2022,
      "journal": "Tomography",
      "volume": "8",
      "number": "2",
      "pages": "905-919",
      "abstract": "There is a growing demand for high-resolution (HR) medical images for both clinical and research applications. Image quality is inevitably traded off with acquisition time, which in turn impacts patient comfort, examination costs, dose, and motion-induced artifacts. For many image-based tasks, increasing the apparent spatial resolution in the perpendicular plane to produce multi-planar reformats or 3D images is commonly used. Single-image super-resolution (SR) is a promising technique to provide HR images based on deep learning to increase the resolution of a 2D image, but there are few reports on 3D SR. Further, perceptual loss is proposed in the literature to better capture the textural details and edges versus pixel-wise loss functions, by comparing the semantic distances in the high-dimensional feature space of a pre-trained 2D network (e.g., VGG). However, it is not clear how one should generalize it to 3D medical images, and the attendant implications are unclear. In this paper, we propose a framework called SOUP-GAN: Super-resolution Optimized Using Perceptual-tuned Generative Adversarial Network (GAN), in order to produce thinner slices (e.g., higher resolution in the Z plane) with anti-aliasing and deblurring. The proposed method outperforms other conventional resolution-enhancement methods and previous SR work on medical images based on both qualitative and quantitative comparisons. Moreover, we examine the model in terms of its generalization for arbitrarily user-selected SR ratios and imaging modalities. Our model shows promise as a novel 3D SR interpolation technique, providing potential applications for both",
      "num_citations": 95,
      "url": "https://www.mdpi.com/2379-139X/8/2/73",
      "article_id": "soup-gan-super-resolution-mri-using-gene-d8f785c9",
      "bibtex": "@article{erickson2022soupgan,\n    author = {Kuan Zhang and Haoji Hu and Kenneth Philbrick and Gian Marco Conte and Joseph D Sobek and Pouria Rouzrokh and Bradley J Erickson},\n    title = {SOUP-GAN: Super-resolution MRI using generative adversarial networks},\n    year = {2022},\n    journal = {Tomography},\n    volume = {8},\n    number = {2},\n    pages = {905-919},\n    note = {soup-gan-super-resolution-mri-using-gene-d8f785c9},\n    url = {https://www.mdpi.com/2379-139X/8/2/73},\n    abstract = {There is a growing demand for high-resolution (HR) medical images for both clinical and research applications. Image quality is inevitably traded off with acquisition time, which in turn impacts patient comfort, examination costs, dose, and motion-induced artifacts. For many image-based tasks, increasing the apparent spatial resolution in the perpendicular plane to produce multi-planar reformats or 3D images is commonly used. Single-image super-resolution (SR) is a promising technique to provide HR images based on deep learning to increase the resolution of a 2D image, but there are few reports on 3D SR. Further, perceptual loss is proposed in the literature to better capture the textural details and edges versus pixel-wise loss functions, by comparing the semantic distances in the high-dimensional feature space of a pre-trained 2D network (e.g., VGG). However, it is not clear how one should generalize it to 3D medical images, and the attendant implications are unclear. In this paper, we propose a framework called SOUP-GAN: Super-resolution Optimized Using Perceptual-tuned Generative Adversarial Network (GAN), in order to produce thinner slices (e.g., higher resolution in the Z plane) with anti-aliasing and deblurring. The proposed method outperforms other conventional resolution-enhancement methods and previous SR work on medical images based on both qualitative and quantitative comparisons. Moreover, we examine the model in terms of its generalization for arbitrarily user-selected SR ratios and imaging modalities. Our model shows promise as a novel 3D SR interpolation technique, providing potential applications for both},\n}"
    },
    {
      "title": "Mitigating bias in radiology machine learning: 3. Performance metrics",
      "authors": "Shahriar Faghani, Bardia Khosravi, Kuan Zhang, Mana Moassefi, Jaidip Manikrao Jagtap, Fred Nugen, Sanaz Vahdati, Shiba P Kuanar, Seyed Moein Rassoulinejad-Mousavi, Yashbir Singh, Diana V Vera Garcia, Pouria Rouzrokh, Bradley J Erickson",
      "year": 2022,
      "journal": "Radiology: Artificial Intelligence",
      "volume": "4",
      "number": "5",
      "pages": "e220061",
      "abstract": "The increasing use of machine learning (ML) algorithms in clinical settings raises concerns about bias in ML models. Bias can arise at any step of ML creation, including data handling, model development, and performance evaluation. Potential biases in the ML model can be minimized by implementing these steps correctly. This report focuses on performance evaluation and discusses model fitness, as well as a set of performance evaluation toolboxes: namely, performance metrics, performance interpretation maps, and uncertainty quantification. By discussing the strengths and limitations of each toolbox, our report highlights strategies and considerations to mitigate and detect biases during performance evaluations of radiology artificial intelligence models.Keywords: Segmentation, Diagnosis",
      "num_citations": 85,
      "url": "https://pubs.rsna.org/doi/abs/10.1148/ryai.220061",
      "article_id": "mitigating-bias-in-radiology-machine-lea-39a11210",
      "bibtex": "@article{erickson2022mitigating,\n    author = {Shahriar Faghani and Bardia Khosravi and Kuan Zhang and Mana Moassefi and Jaidip Manikrao Jagtap and Fred Nugen and Sanaz Vahdati and Shiba P Kuanar and Seyed Moein Rassoulinejad-Mousavi and Yashbir Singh and Diana V Vera Garcia and Pouria Rouzrokh and Bradley J Erickson},\n    title = {Mitigating bias in radiology machine learning: 3. Performance metrics},\n    year = {2022},\n    journal = {Radiology: Artificial Intelligence},\n    volume = {4},\n    number = {5},\n    pages = {e220061},\n    note = {mitigating-bias-in-radiology-machine-lea-39a11210},\n    url = {https://pubs.rsna.org/doi/abs/10.1148/ryai.220061},\n    abstract = {The increasing use of machine learning (ML) algorithms in clinical settings raises concerns about bias in ML models. Bias can arise at any step of ML creation, including data handling, model development, and performance evaluation. Potential biases in the ML model can be minimized by implementing these steps correctly. This report focuses on performance evaluation and discusses model fitness, as well as a set of performance evaluation toolboxes: namely, performance metrics, performance interpretation maps, and uncertainty quantification. By discussing the strengths and limitations of each toolbox, our report highlights strategies and considerations to mitigate and detect biases during performance evaluations of radiology artificial intelligence models.Keywords: Segmentation, Diagnosis},\n}"
    },
    {
      "title": "Mitigating bias in radiology machine learning: 2. Model development",
      "authors": "Kuan Zhang, Bardia Khosravi, Sanaz Vahdati, Shahriar Faghani, Fred Nugen, Seyed Moein Rassoulinejad-Mousavi, Mana Moassefi, Jaidip Manikrao M Jagtap, Yashbir Singh, Pouria Rouzrokh, Bradley J Erickson",
      "year": 2022,
      "volume": "4",
      "number": "5",
      "pages": "e220010",
      "abstract": "There are increasing concerns about the bias and fairness of artificial intelligence (AI) models as they are put into clinical practice. Among the steps for implementing machine learning tools into clinical workflow, model development is an important stage where different types of biases can occur. This report focuses on four aspects of model development where such bias may arise: data augmentation, model and loss function, optimizers, and transfer learning. This report emphasizes appropriate considerations and practices that can mitigate biases in radiology AI studies.Keywords: Model, Bias, Machine Learning, Deep Learning, Radiology RSNA, 2022",
      "num_citations": 84,
      "url": "https://pubs.rsna.org/doi/abs/10.1148/ryai.220010",
      "article_id": "mitigating-bias-in-radiology-machine-lea-b5dd976c",
      "bibtex": "@article{erickson2022mitigating,\n    author = {Kuan Zhang and Bardia Khosravi and Sanaz Vahdati and Shahriar Faghani and Fred Nugen and Seyed Moein Rassoulinejad-Mousavi and Mana Moassefi and Jaidip Manikrao M Jagtap and Yashbir Singh and Pouria Rouzrokh and Bradley J Erickson},\n    title = {Mitigating bias in radiology machine learning: 2. Model development},\n    year = {2022},\n    volume = {4},\n    number = {5},\n    pages = {e220010},\n    note = {mitigating-bias-in-radiology-machine-lea-b5dd976c},\n    url = {https://pubs.rsna.org/doi/abs/10.1148/ryai.220010},\n    abstract = {There are increasing concerns about the bias and fairness of artificial intelligence (AI) models as they are put into clinical practice. Among the steps for implementing machine learning tools into clinical workflow, model development is an important stage where different types of biases can occur. This report focuses on four aspects of model development where such bias may arise: data augmentation, model and loss function, optimizers, and transfer learning. This report emphasizes appropriate considerations and practices that can mitigate biases in radiology AI studies.Keywords: Model, Bias, Machine Learning, Deep Learning, Radiology RSNA, 2022},\n}"
    },
    {
      "title": "Development of a deep learning model for the histologic diagnosis of dysplasia in Barrett\u2019s esophagus",
      "authors": "Shahriar Faghani, D Chamil Codipilly, David Vogelsang, Mana Moassefi, Pouria Rouzrokh, Bardia Khosravi, Siddharth Agarwal, Lovekirat Dhaliwal, David A Katzka, Catherine Hagen, Jason Lewis, Cadman L Leggett, Bradley J Erickson, Prasad G Iyer",
      "year": 2022,
      "journal": "Gastrointestinal endoscopy",
      "volume": "96",
      "number": "6",
      "pages": "918-925. e3",
      "abstract": "Background and AimsThe risk of progression in Barretts esophagus (BE) increases with development of dysplasia. There is a critical need to improve the diagnosis of BE dysplasia, given substantial interobserver disagreement among expert pathologists and overdiagnosis of dysplasia by community pathologists. We developed a deep learning model to predict dysplasia grade on whole-slide imaging.MethodsWe digitized nondysplastic BE (NDBE), low-grade dysplasia (LGD), and high-grade dysplasia (HGD) histology slides. Two expert pathologists confirmed all histology and digitally annotated areas of dysplasia. Training, validation, and test sets were created (by a random 702010 split). We used an ensemble approach combining a you only look once model to identify regions of interest and histology class (NDBE, LGD, or HGD) followed by a ResNet101 model pretrained on ImageNet applied to the regions",
      "num_citations": 43,
      "url": "https://www.sciencedirect.com/science/article/pii/S0016510722017643",
      "article_id": "development-of-a-deep-learning-model-for-f5d7c342",
      "bibtex": "@article{iyer2022development,\n    author = {Shahriar Faghani and D Chamil Codipilly and David Vogelsang and Mana Moassefi and Pouria Rouzrokh and Bardia Khosravi and Siddharth Agarwal and Lovekirat Dhaliwal and David A Katzka and Catherine Hagen and Jason Lewis and Cadman L Leggett and Bradley J Erickson and Prasad G Iyer},\n    title = {Development of a deep learning model for the histologic diagnosis of dysplasia in Barrett\u2019s esophagus},\n    year = {2022},\n    journal = {Gastrointestinal endoscopy},\n    volume = {96},\n    number = {6},\n    pages = {918-925. e3},\n    note = {development-of-a-deep-learning-model-for-f5d7c342},\n    url = {https://www.sciencedirect.com/science/article/pii/S0016510722017643},\n    abstract = {Background and AimsThe risk of progression in Barretts esophagus (BE) increases with development of dysplasia. There is a critical need to improve the diagnosis of BE dysplasia, given substantial interobserver disagreement among expert pathologists and overdiagnosis of dysplasia by community pathologists. We developed a deep learning model to predict dysplasia grade on whole-slide imaging.MethodsWe digitized nondysplastic BE (NDBE), low-grade dysplasia (LGD), and high-grade dysplasia (HGD) histology slides. Two expert pathologists confirmed all histology and digitally annotated areas of dysplasia. Training, validation, and test sets were created (by a random 702010 split). We used an ensemble approach combining a you only look once model to identify regions of interest and histology class (NDBE, LGD, or HGD) followed by a ResNet101 model pretrained on ImageNet applied to the regions},\n}"
    },
    {
      "title": "Applying deep learning to establish a total hip arthroplasty radiography registry: a stepwise approach",
      "authors": "Pouria Rouzrokh, Bardia Khosravi, Quinn J Johnson, Shahriar Faghani, Diana V Vera Garcia, Bradley J Erickson, Hilal Maradit Kremers, Michael J Taunton, Cody C Wyles",
      "year": 2022,
      "journal": "JBJS",
      "volume": "104",
      "number": "18",
      "pages": "1649-1658",
      "abstract": "Background:Establishing imaging registries for large patient cohorts is challenging because manual labeling is tedious and relying solely on DICOM (digital imaging and communications in medicine) metadata can result in errors. We endeavored to establish an automated hip and pelvic radiography registry of total hip arthroplasty (THA) patients by utilizing deep-learning pipelines. The aims of the study were (1) to utilize these automated pipelines to identify all pelvic and hip radiographs with appropriate annotation of laterality and presence or absence of implants, and (2) to automatically measure acetabular component inclination and version for THA images.Methods:We retrospectively retrieved 846,988 hip and pelvic radiography DICOM files from 20,378 patients who underwent primary or revision THA performed at our institution from 2000 to 2020. Metadata for the files were screened followed by extraction of",
      "num_citations": 40,
      "url": "https://journals.lww.com/jbjsjournal/fulltext/2022/09210/applying_deep_learning_to_establish_a_total_hip.7.aspx",
      "article_id": "applying-deep-learning-to-establish-a-to-ae0c49b0",
      "bibtex": "@article{wyles2022applying,\n    author = {Pouria Rouzrokh and Bardia Khosravi and Quinn J Johnson and Shahriar Faghani and Diana V Vera Garcia and Bradley J Erickson and Hilal Maradit Kremers and Michael J Taunton and Cody C Wyles},\n    title = {Applying deep learning to establish a total hip arthroplasty radiography registry: a stepwise approach},\n    year = {2022},\n    journal = {JBJS},\n    volume = {104},\n    number = {18},\n    pages = {1649-1658},\n    note = {applying-deep-learning-to-establish-a-to-ae0c49b0},\n    url = {https://journals.lww.com/jbjsjournal/fulltext/2022/09210/applying\\_deep\\_learning\\_to\\_establish\\_a\\_total\\_hip.7.aspx},\n    abstract = {Background:Establishing imaging registries for large patient cohorts is challenging because manual labeling is tedious and relying solely on DICOM (digital imaging and communications in medicine) metadata can result in errors. We endeavored to establish an automated hip and pelvic radiography registry of total hip arthroplasty (THA) patients by utilizing deep-learning pipelines. The aims of the study were (1) to utilize these automated pipelines to identify all pelvic and hip radiographs with appropriate annotation of laterality and presence or absence of implants, and (2) to automatically measure acetabular component inclination and version for THA images.Methods:We retrospectively retrieved 846,988 hip and pelvic radiography DICOM files from 20,378 patients who underwent primary or revision THA performed at our institution from 2000 to 2020. Metadata for the files were screened followed by extraction of},\n}"
    },
    {
      "title": "Redefining the 3D topography of the acetabular safe zone: a multivariable study evaluating prosthetic hip stability",
      "authors": "Mario Hevesi, Cody C Wyles, Pouria Rouzrokh, Bradley J Erickson, Hilal Maradit-Kremers, David G Lewallen, Michael J Taunton, Robert T Trousdale, Daniel J Berry",
      "year": 2022,
      "journal": "JBJS",
      "volume": "104",
      "number": "3",
      "pages": "239-245",
      "abstract": "Background:Dislocation is the most common reason for early revision following total hip arthroplasty (THA). More than 40 years ago, Lewinnek et al. proposed an acetabular safe zone to avoid dislocation. While novel at the time, their study was substantially limited according to modern standards. The purpose of this study was to determine optimal acetabular cup positioning during THA as well as the effect of surgical approach on the topography of the acetabular safe zone and the hazard of dislocation.Methods:Primary THAs that had been performed at a single institution from 2000 to 2017 were reviewed. Acetabular inclination and anteversion were measured using an artificial intelligence neural network; they were validated with performance testing and comparison with blinded grading by 2 orthopaedic surgeons. Patient demographics and dislocation were noted during follow-up. Multivariable Cox proportional",
      "num_citations": 32,
      "url": "https://journals.lww.com/jbjsjournal/fulltext/2022/02020/redefining_the_3d_topography_of_the_acetabular.6.aspx",
      "article_id": "redefining-the-3d-topography-of-the-acet-84c74909",
      "bibtex": "@article{berry2022redefining,\n    author = {Mario Hevesi and Cody C Wyles and Pouria Rouzrokh and Bradley J Erickson and Hilal Maradit-Kremers and David G Lewallen and Michael J Taunton and Robert T Trousdale and Daniel J Berry},\n    title = {Redefining the 3D topography of the acetabular safe zone: a multivariable study evaluating prosthetic hip stability},\n    year = {2022},\n    journal = {JBJS},\n    volume = {104},\n    number = {3},\n    pages = {239-245},\n    note = {redefining-the-3d-topography-of-the-acet-84c74909},\n    url = {https://journals.lww.com/jbjsjournal/fulltext/2022/02020/redefining\\_the\\_3d\\_topography\\_of\\_the\\_acetabular.6.aspx},\n    abstract = {Background:Dislocation is the most common reason for early revision following total hip arthroplasty (THA). More than 40 years ago, Lewinnek et al. proposed an acetabular safe zone to avoid dislocation. While novel at the time, their study was substantially limited according to modern standards. The purpose of this study was to determine optimal acetabular cup positioning during THA as well as the effect of surgical approach on the topography of the acetabular safe zone and the hazard of dislocation.Methods:Primary THAs that had been performed at a single institution from 2000 to 2017 were reviewed. Acetabular inclination and anteversion were measured using an artificial intelligence neural network; they were validated with performance testing and comparison with blinded grading by 2 orthopaedic surgeons. Patient demographics and dislocation were noted during follow-up. Multivariable Cox proportional},\n}"
    },
    {
      "title": "Multitask brain tumor inpainting with diffusion models: a methodological report",
      "authors": "Pouria Rouzrokh, Bardia Khosravi, Shahriar Faghani, Mana Moassefi, Sanaz Vahdati, Bradley J Erickson",
      "year": 2022,
      "journal": "arXiv preprint arXiv:2210.12113",
      "abstract": "Despite the ever-increasing interest in applying deep learning (DL) models to medical imaging, the typical scarcity and imbalance of medical datasets can severely impact the performance of DL models. The generation of synthetic data that might be freely shared without compromising patient privacy is a well-known technique for addressing these difficulties. Inpainting algorithms are a subset of DL generative models that can alter one or more regions of an input image while matching its surrounding context and, in certain cases, non-imaging input conditions. Although the majority of inpainting techniques for medical imaging data use generative adversarial networks (GANs), the performance of these algorithms is frequently suboptimal due to their limited output variety, a problem that is already well-known for GANs. Denoising diffusion probabilistic models (DDPMs) are a recently introduced family of generative networks that can generate results of comparable quality to GANs, but with diverse outputs. In this paper, we describe a DDPM to execute multiple inpainting tasks on 2D axial slices of brain MRI with various sequences, and present proof-of-concept examples of its performance in a variety of evaluation scenarios. Our model and a public online interface to try our tool are available at: https:github.comMayo-Radiology-Informatics-LabMBTI",
      "num_citations": 27,
      "url": "https://arxiv.org/abs/2210.12113",
      "article_id": "multitask-brain-tumor-inpainting-with-di-fb56bf29",
      "bibtex": "@article{erickson2022multitask,\n    author = {Pouria Rouzrokh and Bardia Khosravi and Shahriar Faghani and Mana Moassefi and Sanaz Vahdati and Bradley J Erickson},\n    title = {Multitask brain tumor inpainting with diffusion models: a methodological report},\n    year = {2022},\n    journal = {arXiv preprint arXiv:2210.12113},\n    note = {multitask-brain-tumor-inpainting-with-di-fb56bf29},\n    url = {https://arxiv.org/abs/2210.12113},\n    abstract = {Despite the ever-increasing interest in applying deep learning (DL) models to medical imaging, the typical scarcity and imbalance of medical datasets can severely impact the performance of DL models. The generation of synthetic data that might be freely shared without compromising patient privacy is a well-known technique for addressing these difficulties. Inpainting algorithms are a subset of DL generative models that can alter one or more regions of an input image while matching its surrounding context and, in certain cases, non-imaging input conditions. Although the majority of inpainting techniques for medical imaging data use generative adversarial networks (GANs), the performance of these algorithms is frequently suboptimal due to their limited output variety, a problem that is already well-known for GANs. Denoising diffusion probabilistic models (DDPMs) are a recently introduced family of generative networks that can generate results of comparable quality to GANs, but with diverse outputs. In this paper, we describe a DDPM to execute multiple inpainting tasks on 2D axial slices of brain MRI with various sequences, and present proof-of-concept examples of its performance in a variety of evaluation scenarios. Our model and a public online interface to try our tool are available at: https:github.comMayo-Radiology-Informatics-LabMBTI},\n}"
    },
    {
      "title": "Patient-specific hip arthroplasty dislocation risk calculator: an explainable multimodal machine learning\u2013based approach",
      "authors": "Bardia Khosravi, Pouria Rouzrokh, Hilal Maradit Kremers, Dirk R Larson, Quinn J Johnson, Shahriar Faghani, Walter K Kremers, Bradley J Erickson, Rafael J Sierra, Michael J Taunton, Cody C Wyles",
      "year": 2022,
      "journal": "Radiology: Artificial Intelligence",
      "volume": "4",
      "number": "6",
      "pages": "e220067",
      "abstract": "To develop a multimodal machine learningbased pipeline to predict patient-specific risk of dislocation following primary total hip arthroplasty (THA).This study retrospectively evaluated 17 073 patients who underwent primary THA between 1998 and 2018. A test set of 1718 patients was held out. A hybrid network of EfficientNet-B4 and Swin-B transformer was developed to classify patients according to 5-year dislocation outcomes from preoperative anteroposterior pelvic radiographs and clinical characteristics (demographics, comorbidities, and surgical characteristics). The most informative imaging features, extracted by the mentioned model, were",
      "num_citations": 28,
      "url": "https://pubs.rsna.org/doi/abs/10.1148/ryai.220067",
      "article_id": "patient-specific-hip-arthroplasty-disloc-be24da64",
      "bibtex": "@article{wyles2022patientspecific,\n    author = {Bardia Khosravi and Pouria Rouzrokh and Hilal Maradit Kremers and Dirk R Larson and Quinn J Johnson and Shahriar Faghani and Walter K Kremers and Bradley J Erickson and Rafael J Sierra and Michael J Taunton and Cody C Wyles},\n    title = {Patient-specific hip arthroplasty dislocation risk calculator: an explainable multimodal machine learning\u2013based approach},\n    year = {2022},\n    journal = {Radiology: Artificial Intelligence},\n    volume = {4},\n    number = {6},\n    pages = {e220067},\n    note = {patient-specific-hip-arthroplasty-disloc-be24da64},\n    url = {https://pubs.rsna.org/doi/abs/10.1148/ryai.220067},\n    abstract = {To develop a multimodal machine learningbased pipeline to predict patient-specific risk of dislocation following primary total hip arthroplasty (THA).This study retrospectively evaluated 17 073 patients who underwent primary THA between 1998 and 2018. A test set of 1718 patients was held out. A hybrid network of EfficientNet-B4 and Swin-B transformer was developed to classify patients according to 5-year dislocation outcomes from preoperative anteroposterior pelvic radiographs and clinical characteristics (demographics, comorbidities, and surgical characteristics). The most informative imaging features, extracted by the mentioned model, were},\n}"
    },
    {
      "title": "Distribution and correlates of hip-knee-ankle angle in early osteoarthritis and preoperative total knee arthroplasty patients",
      "authors": "Taghi Ramazanian, Shi Yan, Pouria Rouzrokh, Cody C Wyles, Thomas JO Byrne, Michael J Taunton, Hilal Maradit Kremers",
      "year": 2022,
      "journal": "The Journal of arthroplasty",
      "volume": "37",
      "number": "6",
      "pages": "S170-S175",
      "abstract": "Several studies have investigated the distribution of hip-knee-ankle (HKA) angle in healthy populations; however, few have evaluated this metric in patients undergoing total knee arthroplasty (TKA). The purpose of this study is to compare HKA angle distribution in early and advanced knee osteoarthritis (OA) patients.Full limb radiographs were used to measure HKA angle for 983 subjects from the Osteoarthritis Initiative (OAI) cohort and 4,901 pre-TKA patients from an institutional cohort. Measurements were made using a previously validated deep learning algorithm. Linear regression models were used to determine the association of HKA alignment angle with patient characteristics.The mean standard deviation HKA angle was 1.3 3.2 in the OAI cohort and 4.1 6.1 in the pre-TKA cohort. In the OAI cohort, normal alignment (64) was the most common knee alignment",
      "num_citations": 24,
      "url": "https://www.sciencedirect.com/science/article/pii/S088354032100944X",
      "article_id": "distribution-and-correlates-of-hip-knee--70e12520",
      "bibtex": "@article{kremers2022distribution,\n    author = {Taghi Ramazanian and Shi Yan and Pouria Rouzrokh and Cody C Wyles and Thomas JO Byrne and Michael J Taunton and Hilal Maradit Kremers},\n    title = {Distribution and correlates of hip-knee-ankle angle in early osteoarthritis and preoperative total knee arthroplasty patients},\n    year = {2022},\n    journal = {The Journal of arthroplasty},\n    volume = {37},\n    number = {6},\n    pages = {S170-S175},\n    note = {distribution-and-correlates-of-hip-knee--70e12520},\n    url = {https://www.sciencedirect.com/science/article/pii/S088354032100944X},\n    abstract = {Several studies have investigated the distribution of hip-knee-ankle (HKA) angle in healthy populations; however, few have evaluated this metric in patients undergoing total knee arthroplasty (TKA). The purpose of this study is to compare HKA angle distribution in early and advanced knee osteoarthritis (OA) patients.Full limb radiographs were used to measure HKA angle for 983 subjects from the Osteoarthritis Initiative (OAI) cohort and 4,901 pre-TKA patients from an institutional cohort. Measurements were made using a previously validated deep learning algorithm. Linear regression models were used to determine the association of HKA alignment angle with patient characteristics.The mean standard deviation HKA angle was 1.3 3.2 in the OAI cohort and 4.1 6.1 in the pre-TKA cohort. In the OAI cohort, normal alignment (64) was the most common knee alignment},\n}"
    },
    {
      "title": "Deep learning for radiographic measurement of femoral component subsidence following total hip arthroplasty",
      "authors": "Pouria Rouzrokh, Cody C Wyles, Shyam J Kurian, Taghi Ramazanian, Jason C Cai, Qiao Huang, Kuan Zhang, Michael J Taunton, Hilal Maradit Kremers, Bradley J Erickson",
      "year": 2022,
      "journal": "Radiology: Artificial Intelligence",
      "volume": "4",
      "number": "3",
      "pages": "e210206",
      "abstract": "Femoral component subsidence following total hip arthroplasty (THA) is a worrisome radiographic finding. This study developed and evaluated a deep learning tool to automatically quantify femoral component subsidence between two serial anteroposterior (AP) hip radiographs. The authors institutional arthroplasty registry was used to retrospectively identify patients who underwent primary THA from 2000 to 2020. A deep learning dynamic U-Net model was trained to automatically segment femur, implant, and magnification markers on a dataset of 500 randomly selected AP hip radiographs from 386 patients with polished tapered cemented femoral stems. An image processing algorithm was then developed to measure subsidence by automatically annotating reference points on the femur and implant",
      "num_citations": 21,
      "url": "https://pubs.rsna.org/doi/abs/10.1148/ryai.210206",
      "article_id": "deep-learning-for-radiographic-measureme-fe73463e",
      "bibtex": "@article{erickson2022deep,\n    author = {Pouria Rouzrokh and Cody C Wyles and Shyam J Kurian and Taghi Ramazanian and Jason C Cai and Qiao Huang and Kuan Zhang and Michael J Taunton and Hilal Maradit Kremers and Bradley J Erickson},\n    title = {Deep learning for radiographic measurement of femoral component subsidence following total hip arthroplasty},\n    year = {2022},\n    journal = {Radiology: Artificial Intelligence},\n    volume = {4},\n    number = {3},\n    pages = {e210206},\n    note = {deep-learning-for-radiographic-measureme-fe73463e},\n    url = {https://pubs.rsna.org/doi/abs/10.1148/ryai.210206},\n    abstract = {Femoral component subsidence following total hip arthroplasty (THA) is a worrisome radiographic finding. This study developed and evaluated a deep learning tool to automatically quantify femoral component subsidence between two serial anteroposterior (AP) hip radiographs. The authors institutional arthroplasty registry was used to retrospectively identify patients who underwent primary THA from 2000 to 2020. A deep learning dynamic U-Net model was trained to automatically segment femur, implant, and magnification markers on a dataset of 500 randomly selected AP hip radiographs from 386 patients with polished tapered cemented femoral stems. An image processing algorithm was then developed to measure subsidence by automatically annotating reference points on the femur and implant},\n}"
    },
    {
      "title": "Diagnostic performance of clinical examination versus ultrasonography in the detection of developmental dysplasia of hip: A systematic review and meta-analysis",
      "authors": "Mohammadreza Chavoshi, Ghazaleh Soltani, Shekoufe Shafiei Zargar, Cody Clayton Wyles, Hilal Maradit Kremers, Pouria Rouzrokh",
      "year": 2022,
      "volume": "10",
      "number": "5",
      "pages": "403",
      "num_citations": 16,
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC9194706/",
      "article_id": "diagnostic-performance-of-clinical-exami-006d2a9f",
      "bibtex": "@article{rouzrokh2022diagnostic,\n    author = {Mohammadreza Chavoshi and Ghazaleh Soltani and Shekoufe Shafiei Zargar and Cody Clayton Wyles and Hilal Maradit Kremers and Pouria Rouzrokh},\n    title = {Diagnostic performance of clinical examination versus ultrasonography in the detection of developmental dysplasia of hip: A systematic review and meta-analysis},\n    year = {2022},\n    volume = {10},\n    number = {5},\n    pages = {403},\n    note = {diagnostic-performance-of-clinical-exami-006d2a9f},\n    url = {https://pmc.ncbi.nlm.nih.gov/articles/PMC9194706/},\n}"
    },
    {
      "title": "Getting more out of large databases and EHRs with natural language processing and artificial intelligence: the future is here",
      "authors": "Bardia Khosravi, Pouria Rouzrokh, Bradley J Erickson",
      "year": 2022,
      "volume": "104",
      "number": "Suppl 3",
      "pages": "51-55",
      "abstract": "Electronic health records (EHRs) have created great opportunities to collect various information from clinical patient encounters. However, most EHR data are stored in unstructured form (eg, clinical notes, surgical notes, and medication instructions), and researchers need data to be in computable form (structured) to extract meaningful relationships involving variables that can influence patient outcomes. Clinical natural language processing (NLP) is the field of extracting structured data from unstructured text documents in EHRs. Clinical text has several characteristics that mandate the use of special techniques to extract structured information from them compared with generic NLP methods. In this article, we define clinical NLP models, introduce different methods of information extraction from unstructured data using NLP, and describe the basic technical aspects of how deep learning-based NLP models work. We",
      "num_citations": 13,
      "url": "https://journals.lww.com/jbjsjournal/fulltext/2022/10191/Getting_More_Out_of_Large_Databases_and_EHRs_with.12.aspx",
      "article_id": "getting-more-out-of-large-databases-and--249282b2",
      "bibtex": "@article{erickson2022getting,\n    author = {Bardia Khosravi and Pouria Rouzrokh and Bradley J Erickson},\n    title = {Getting more out of large databases and EHRs with natural language processing and artificial intelligence: the future is here},\n    year = {2022},\n    volume = {104},\n    number = {Suppl 3},\n    pages = {51-55},\n    note = {getting-more-out-of-large-databases-and--249282b2},\n    url = {https://journals.lww.com/jbjsjournal/fulltext/2022/10191/Getting\\_More\\_Out\\_of\\_Large\\_Databases\\_and\\_EHRs\\_with.12.aspx},\n    abstract = {Electronic health records (EHRs) have created great opportunities to collect various information from clinical patient encounters. However, most EHR data are stored in unstructured form (eg, clinical notes, surgical notes, and medication instructions), and researchers need data to be in computable form (structured) to extract meaningful relationships involving variables that can influence patient outcomes. Clinical natural language processing (NLP) is the field of extracting structured data from unstructured text documents in EHRs. Clinical text has several characteristics that mandate the use of special techniques to extract structured information from them compared with generic NLP methods. In this article, we define clinical NLP models, introduce different methods of information extraction from unstructured data using NLP, and describe the basic technical aspects of how deep learning-based NLP models work. We},\n}"
    },
    {
      "title": "Machine Learning and Deep Learning in Cardiothoracic Imaging: A Scoping Review",
      "authors": "Bardia Khosravi, Pouria Rouzrokh, Shahriar Faghani, Mana Moassefi, Sanaz Vahdati, Elham Mahmoudi, Hamid Chalian, Bradley J Erickson",
      "year": 2022,
      "volume": "12",
      "number": "10",
      "pages": "2512",
      "abstract": "Machine-learning (ML) and deep-learning (DL) algorithms are part of a group of modeling algorithms that grasp the hidden patterns in data based on a training process, enabling them to extract complex information from the input data. In the past decade, these algorithms have been increasingly used for image processing, specifically in the medical domain. Cardiothoracic imaging is one of the early adopters of MLDL research, and the COVID-19 pandemic resulted in more research focus on the feasibility and applications of MLDL in cardiothoracic imaging. In this scoping review, we systematically searched available peer-reviewed medical literature on cardiothoracic imaging and quantitatively extracted key data elements in order to get a big picture of how MLDL have been used in the rapidly evolving cardiothoracic imaging field. During this report, we provide insights on different applications of MLDL and some nuances pertaining to this specific field of research. Finally, we provide general suggestions on how researchers can make their research more than just a proof-of-concept and move toward clinical adoption.",
      "num_citations": 5,
      "url": "https://www.mdpi.com/2075-4418/12/10/2512",
      "article_id": "machine-learning-and-deep-learning-in-ca-c6ea4890",
      "bibtex": "@article{erickson2022machine,\n    author = {Bardia Khosravi and Pouria Rouzrokh and Shahriar Faghani and Mana Moassefi and Sanaz Vahdati and Elham Mahmoudi and Hamid Chalian and Bradley J Erickson},\n    title = {Machine Learning and Deep Learning in Cardiothoracic Imaging: A Scoping Review},\n    year = {2022},\n    volume = {12},\n    number = {10},\n    pages = {2512},\n    note = {machine-learning-and-deep-learning-in-ca-c6ea4890},\n    url = {https://www.mdpi.com/2075-4418/12/10/2512},\n    abstract = {Machine-learning (ML) and deep-learning (DL) algorithms are part of a group of modeling algorithms that grasp the hidden patterns in data based on a training process, enabling them to extract complex information from the input data. In the past decade, these algorithms have been increasingly used for image processing, specifically in the medical domain. Cardiothoracic imaging is one of the early adopters of MLDL research, and the COVID-19 pandemic resulted in more research focus on the feasibility and applications of MLDL in cardiothoracic imaging. In this scoping review, we systematically searched available peer-reviewed medical literature on cardiothoracic imaging and quantitatively extracted key data elements in order to get a big picture of how MLDL have been used in the rapidly evolving cardiothoracic imaging field. During this report, we provide insights on different applications of MLDL and some nuances pertaining to this specific field of research. Finally, we provide general suggestions on how researchers can make their research more than just a proof-of-concept and move toward clinical adoption.},\n}"
    },
    {
      "title": "NEIM-02 DEVELOPMENT OF A DEEP LEARNING MODEL FOR DISCRIMINATING TRUE PROGRESSION FROM PSEUDOPROGRESSION IN GLIOBLASTOMA PATIENTS",
      "authors": "Mana Moassefi, Shahriar Faghani, Gian Marco Conte, Pouria Rouzrokh, Roman O Kowalchuk, Daniel Trifiletti, BradleyJ Erickson",
      "year": 2022,
      "journal": "Neuro-oncology Advances",
      "volume": "4",
      "number": "Suppl 1",
      "pages": "i17",
      "abstract": "INTRODUCTION Glioblastomas (GBMs) are highly aggressive tumors. Despite multimodal treatment, its median overall survival ranges between 16 and 20 months. The standard treatment regimen consists of surgical resection followed by concurrent chemoradiotherapy and adjuvant temozolomide. Despite temozolomides effectiveness, it may cause the clinical challenge of treatment-related progression also known as pseudoprogression(PsP). Usually, PSP resolves or stabilizes without further treatment, whereas a true progression (TP) requires more aggressive management. Identifying PSP from TP will affect the patients treatment plan. Conventional magnetic resonance imaging (MRI) reading techniques cannot distinguish these entities. This study investigated the feasibility of using deep learning to distinguish PsP from TP. METHOD We included GBM patients who met our inclusion criteria. We evaluated all",
      "num_citations": 0,
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC9354212/",
      "article_id": "neim-02-development-of-a-deep-learning-m-9a77fc24",
      "bibtex": "@article{erickson2022neim02,\n    author = {Mana Moassefi and Shahriar Faghani and Gian Marco Conte and Pouria Rouzrokh and Roman O Kowalchuk and Daniel Trifiletti and BradleyJ Erickson},\n    title = {NEIM-02 DEVELOPMENT OF A DEEP LEARNING MODEL FOR DISCRIMINATING TRUE PROGRESSION FROM PSEUDOPROGRESSION IN GLIOBLASTOMA PATIENTS},\n    year = {2022},\n    journal = {Neuro-oncology Advances},\n    volume = {4},\n    number = {Suppl 1},\n    pages = {i17},\n    note = {neim-02-development-of-a-deep-learning-m-9a77fc24},\n    url = {https://pmc.ncbi.nlm.nih.gov/articles/PMC9354212/},\n    abstract = {INTRODUCTION Glioblastomas (GBMs) are highly aggressive tumors. Despite multimodal treatment, its median overall survival ranges between 16 and 20 months. The standard treatment regimen consists of surgical resection followed by concurrent chemoradiotherapy and adjuvant temozolomide. Despite temozolomides effectiveness, it may cause the clinical challenge of treatment-related progression also known as pseudoprogression(PsP). Usually, PSP resolves or stabilizes without further treatment, whereas a true progression (TP) requires more aggressive management. Identifying PSP from TP will affect the patients treatment plan. Conventional magnetic resonance imaging (MRI) reading techniques cannot distinguish these entities. This study investigated the feasibility of using deep learning to distinguish PsP from TP. METHOD We included GBM patients who met our inclusion criteria. We evaluated all},\n}"
    },
    {
      "title": "Development of a Deep Learning Model for Whole Slide Image Analysis in the Histologic Diagnosis of Dysplastic Barrett\u2019s Esophagus",
      "authors": "Shahriar Faghani, Don C Codipilly, David Vogelsang, Siddharth Agarwal, Lovekirat S Dhaliwal, Karan Sachdeva, Erin Gibbons, Ramona Lansing, Cadman L Leggett, David A Katzka, Mana Moassefi, Pouria Rouzrokh, Bardia Khosravi, Catherine E Hagen, Jason T Lewis, Bradley Erickson, Prasad G Iyer",
      "year": 2022,
      "volume": "162",
      "number": "7",
      "pages": "S172-S172",
      "abstract": "Barretts esophagus (BE) is the only known precursor lesion of esophageal adenocarcinoma (EAC), and progression occurs via the development of dysplasia. While endoscopic eradication therapy is recommended for high grade dysplasia (HGD), controversy exists regarding optimal management of low-grade dysplasia (LGD). Poor interobserver agreement amongst expert pathologists results in a significant proportion of community-based diagnoses of LGD being downgraded by expert gastrointestinal (GI) pathologists. The presence of confirmed LGD increases the risk of malignant transformation, and the inability to reliably diagnose LGD results in unnecessary procedures. Therefore, improving LGD diagnostic capabilities is critical. We developed a deep learning model leveraging whole slide image (WSI) processing, object detection, and classification to grade BE dysplasia.",
      "num_citations": 0,
      "url": "https://siim.org/wp-content/uploads/2023/08/1014_-_faghani_shahriar__de.pdf",
      "article_id": "development-of-a-deep-learning-model-for-a8eec78f",
      "bibtex": "@article{iyer2022development,\n    author = {Shahriar Faghani and Don C Codipilly and David Vogelsang and Siddharth Agarwal and Lovekirat S Dhaliwal and Karan Sachdeva and Erin Gibbons and Ramona Lansing and Cadman L Leggett and David A Katzka and Mana Moassefi and Pouria Rouzrokh and Bardia Khosravi and Catherine E Hagen and Jason T Lewis and Bradley Erickson and Prasad G Iyer},\n    title = {Development of a Deep Learning Model for Whole Slide Image Analysis in the Histologic Diagnosis of Dysplastic Barrett\u2019s Esophagus},\n    year = {2022},\n    volume = {162},\n    number = {7},\n    pages = {S172-S172},\n    note = {development-of-a-deep-learning-model-for-a8eec78f},\n    url = {https://siim.org/wp-content/uploads/2023/08/1014\\_-\\_faghani\\_shahriar\\_\\_de.pdf},\n    abstract = {Barretts esophagus (BE) is the only known precursor lesion of esophageal adenocarcinoma (EAC), and progression occurs via the development of dysplasia. While endoscopic eradication therapy is recommended for high grade dysplasia (HGD), controversy exists regarding optimal management of low-grade dysplasia (LGD). Poor interobserver agreement amongst expert pathologists results in a significant proportion of community-based diagnoses of LGD being downgraded by expert gastrointestinal (GI) pathologists. The presence of confirmed LGD increases the risk of malignant transformation, and the inability to reliably diagnose LGD results in unnecessary procedures. Therefore, improving LGD diagnostic capabilities is critical. We developed a deep learning model leveraging whole slide image (WSI) processing, object detection, and classification to grade BE dysplasia.},\n}"
    },
    {
      "title": "A deep learning tool for automated radiographic measurement of acetabular component inclination and version after total hip arthroplasty",
      "authors": "Pouria Rouzrokh, Cody C Wyles, Kenneth A Philbrick, Taghi Ramazanian, Alexander D Weston, Jason C Cai, Michael J Taunton, David G Lewallen, Daniel J Berry, Bradley J Erickson, Hilal Maradit Kremers",
      "year": 2021,
      "journal": "The Journal of arthroplasty",
      "volume": "36",
      "number": "7",
      "pages": "2510-2517. e6",
      "abstract": "Inappropriate acetabular component angular position is believed to increase the risk of hip dislocation after total hip arthroplasty. However, manual measurement of these angles is time consuming and prone to interobserver variability. The purpose of this study was to develop a deep learning tool to automate the measurement of acetabular component angles on postoperative radiographs.Two cohorts of 600 anteroposterior (AP) pelvis and 600 cross-table lateral hip postoperative radiographs were used to develop deep learning models to segment the acetabular component and the ischial tuberosities. Cohorts were manually annotated, augmented, and randomly split to train-validation-test data sets on an 8:1:1 basis. Two U-Net convolutional neural network models (one for AP and one for cross-table lateral radiographs) were trained for 50 epochs. Image processing was then deployed to",
      "num_citations": 104,
      "url": "https://www.sciencedirect.com/science/article/pii/S0883540321001650",
      "article_id": "a-deep-learning-tool-for-automated-radio-dbe99049",
      "bibtex": "@article{kremers2021a,\n    author = {Pouria Rouzrokh and Cody C Wyles and Kenneth A Philbrick and Taghi Ramazanian and Alexander D Weston and Jason C Cai and Michael J Taunton and David G Lewallen and Daniel J Berry and Bradley J Erickson and Hilal Maradit Kremers},\n    title = {A deep learning tool for automated radiographic measurement of acetabular component inclination and version after total hip arthroplasty},\n    year = {2021},\n    journal = {The Journal of arthroplasty},\n    volume = {36},\n    number = {7},\n    pages = {2510-2517. e6},\n    note = {a-deep-learning-tool-for-automated-radio-dbe99049},\n    url = {https://www.sciencedirect.com/science/article/pii/S0883540321001650},\n    abstract = {Inappropriate acetabular component angular position is believed to increase the risk of hip dislocation after total hip arthroplasty. However, manual measurement of these angles is time consuming and prone to interobserver variability. The purpose of this study was to develop a deep learning tool to automate the measurement of acetabular component angles on postoperative radiographs.Two cohorts of 600 anteroposterior (AP) pelvis and 600 cross-table lateral hip postoperative radiographs were used to develop deep learning models to segment the acetabular component and the ischial tuberosities. Cohorts were manually annotated, augmented, and randomly split to train-validation-test data sets on an 8:1:1 basis. Two U-Net convolutional neural network models (one for AP and one for cross-table lateral radiographs) were trained for 50 epochs. Image processing was then deployed to},\n}"
    },
    {
      "title": "Deep learning artificial intelligence model for assessment of hip dislocation risk following primary total hip arthroplasty from postoperative radiographs",
      "authors": "Pouria Rouzrokh, Taghi Ramazanian, Cody C Wyles, Kenneth A Philbrick, Jason C Cai, Michael J Taunton, Hilal Maradit Kremers, David G Lewallen, Bradley J Erickson",
      "year": 2021,
      "journal": "The Journal of arthroplasty",
      "volume": "36",
      "number": "6",
      "pages": "2197-2203. e3",
      "abstract": "Dislocation is a common complication following total hip arthroplasty (THA), and accounts for a high percentage of subsequent revisions. The purpose of this study is to illustrate the potential of a convolutional neural network model to assess the risk of hip dislocation based on postoperative anteroposterior pelvis radiographs.We retrospectively evaluated radiographs for a cohort of 13,970 primary THAs with 374 dislocations over 5 years of follow-up. Overall, 1490 radiographs from dislocated and 91,094 from non-dislocated THAs were included in the analysis. A convolutional neural network object detection model (YOLO-V3) was trained to crop the images by centering on the femoral head. A ResNet18 classifier was trained to predict subsequent hip dislocation from the cropped imaging. The ResNet18 classifier was initialized with ImageNet weights and trained using FastAI (V1.0) running on",
      "num_citations": 69,
      "url": "https://www.sciencedirect.com/science/article/pii/S0883540321001674",
      "article_id": "deep-learning-artificial-intelligence-mo-9f79f547",
      "bibtex": "@article{erickson2021deep,\n    author = {Pouria Rouzrokh and Taghi Ramazanian and Cody C Wyles and Kenneth A Philbrick and Jason C Cai and Michael J Taunton and Hilal Maradit Kremers and David G Lewallen and Bradley J Erickson},\n    title = {Deep learning artificial intelligence model for assessment of hip dislocation risk following primary total hip arthroplasty from postoperative radiographs},\n    year = {2021},\n    journal = {The Journal of arthroplasty},\n    volume = {36},\n    number = {6},\n    pages = {2197-2203. e3},\n    note = {deep-learning-artificial-intelligence-mo-9f79f547},\n    url = {https://www.sciencedirect.com/science/article/pii/S0883540321001674},\n    abstract = {Dislocation is a common complication following total hip arthroplasty (THA), and accounts for a high percentage of subsequent revisions. The purpose of this study is to illustrate the potential of a convolutional neural network model to assess the risk of hip dislocation based on postoperative anteroposterior pelvis radiographs.We retrospectively evaluated radiographs for a cohort of 13,970 primary THAs with 374 dislocations over 5 years of follow-up. Overall, 1490 radiographs from dislocated and 91,094 from non-dislocated THAs were included in the analysis. A convolutional neural network object detection model (YOLO-V3) was trained to crop the images by centering on the femoral head. A ResNet18 classifier was trained to predict subsequent hip dislocation from the cropped imaging. The ResNet18 classifier was initialized with ImageNet weights and trained using FastAI (V1.0) running on},\n}"
    },
    {
      "title": "Persistent homology approach distinguishes potential pattern between \u201cEarly\u201d and \u201cNot Early\u201d hepatic decompensation groups using MRI modalities",
      "authors": "Yashbir Singh, William Jons, Gian Marco Conte, Jaidip Jagtap, Kuan Zhang, Joseph D Sobek, Pouria Rouzrokh, John E Eaton, Bradley J Erickson",
      "year": 2021,
      "journal": "Current Directions in Biomedical Engineering",
      "volume": "7",
      "number": "2",
      "pages": "488-491",
      "abstract": "Primary sclerosis cholangitis (PSC) predisposes individuals to liver failure, but it is challenging for radiologists examining radiologic images to predict which patients with PSC will ultimately develop liver failure. Motivated by algebraic topology, a topological data analysis - inspired framework was adopted in the study of the imaging pattern between the Early Decompensation and Not Early groups. The results demonstrate that the proposed methodology discriminates Early Decompensation and Not Early groups. Our study is the first attempt to provide a topological representation-based method into early hepatic decompensation and not early groups.",
      "num_citations": 4,
      "url": "https://www.degruyter.com/document/doi/10.1515/cdbme-2021-2124/html",
      "article_id": "persistent-homology-approach-distinguish-ab3e55c7",
      "bibtex": "@article{erickson2021persistent,\n    author = {Yashbir Singh and William Jons and Gian Marco Conte and Jaidip Jagtap and Kuan Zhang and Joseph D Sobek and Pouria Rouzrokh and John E Eaton and Bradley J Erickson},\n    title = {Persistent homology approach distinguishes potential pattern between \u201cEarly\u201d and \u201cNot Early\u201d hepatic decompensation groups using MRI modalities},\n    year = {2021},\n    journal = {Current Directions in Biomedical Engineering},\n    volume = {7},\n    number = {2},\n    pages = {488-491},\n    note = {persistent-homology-approach-distinguish-ab3e55c7},\n    url = {https://www.degruyter.com/document/doi/10.1515/cdbme-2021-2124/html},\n    abstract = {Primary sclerosis cholangitis (PSC) predisposes individuals to liver failure, but it is challenging for radiologists examining radiologic images to predict which patients with PSC will ultimately develop liver failure. Motivated by algebraic topology, a topological data analysis - inspired framework was adopted in the study of the imaging pattern between the Early Decompensation and Not Early groups. The results demonstrate that the proposed methodology discriminates Early Decompensation and Not Early groups. Our study is the first attempt to provide a topological representation-based method into early hepatic decompensation and not early groups.},\n}"
    },
    {
      "title": "Fully automated segmentation of head CT neuroanatomy using deep learning",
      "authors": "Jason C Cai, Zeynettin Akkus, Kenneth A Philbrick, Arunnit Boonrod, Safa Hoodeshenas, Alexander D Weston, Pouria Rouzrokh, Gian Marco Conte, Atefeh Zeinoddini, David C Vogelsang, Qiao Huang, Bradley J Erickson",
      "year": 2020,
      "journal": "Radiology: Artificial Intelligence",
      "volume": "2",
      "number": "5",
      "pages": "e190183",
      "abstract": "To develop a deep learning model that segments intracranial structures on head CT scans.In this retrospective study, a primary dataset containing 62 normal noncontrast head CT scans from 62 patients (mean age, 73 years; age range, 2795 years) acquired between August and December 2018 was used for model development. Eleven intracranial structures were manually annotated on the axial oblique series. The dataset was split into 40 scans for training, 10 for validation, and 12 for testing. After initial training, eight model configurations were evaluated on the validation dataset and the highest performing model was evaluated on the test dataset",
      "num_citations": 45,
      "url": "https://pubs.rsna.org/doi/abs/10.1148/ryai.2020190183",
      "article_id": "fully-automated-segmentation-of-head-ct--d962da09",
      "bibtex": "@article{erickson2020fully,\n    author = {Jason C Cai and Zeynettin Akkus and Kenneth A Philbrick and Arunnit Boonrod and Safa Hoodeshenas and Alexander D Weston and Pouria Rouzrokh and Gian Marco Conte and Atefeh Zeinoddini and David C Vogelsang and Qiao Huang and Bradley J Erickson},\n    title = {Fully automated segmentation of head CT neuroanatomy using deep learning},\n    year = {2020},\n    journal = {Radiology: Artificial Intelligence},\n    volume = {2},\n    number = {5},\n    pages = {e190183},\n    note = {fully-automated-segmentation-of-head-ct--d962da09},\n    url = {https://pubs.rsna.org/doi/abs/10.1148/ryai.2020190183},\n    abstract = {To develop a deep learning model that segments intracranial structures on head CT scans.In this retrospective study, a primary dataset containing 62 normal noncontrast head CT scans from 62 patients (mean age, 73 years; age range, 2795 years) acquired between August and December 2018 was used for model development. Eleven intracranial structures were manually annotated on the axial oblique series. The dataset was split into 40 scans for training, 10 for validation, and 12 for testing. After initial training, eight model configurations were evaluated on the validation dataset and the highest performing model was evaluated on the test dataset},\n}"
    },
    {
      "title": "Prognostic factors of chest CT findings for ICU admission and mortality in patients with COVID-19 pneumonia",
      "authors": "Mohammad Ali Kazemi, Hossein Ghanaati, Behnaz Moradi, Mohammadreza Chavoshi, Hassan Hashemi, Samira Hemmati, Pouria Rouzrokh, Masoumeh Gity, Zahra Ahmadinejad, Hamed Abdollahi",
      "year": 2020,
      "journal": "MedRxiv",
      "pages": "2020.10. 30.20223024",
      "abstract": "Studies have shown that CT could be valuable for prognostic issues in COVID-19to investigate the prognostic factors of early chest CT findings in COVID-19 patients.This retrospective study included 91 patients (34 women, and 57 men) of RT-PCR positive COVID-19 from 3 hospitals in Iran between February 25, 2020, to march 15, 2020. Patients were divided into two groups as good prognosis, discharged from the hospital and alive without symptoms (48 patients), and poor prognosis, died or needed ICU care (43 patients). The first CT images of both groups that were obtained during the first 8 days of the disease presentation were evaluated considering the pattern, distribution, and underlying disease. The total CT-score was calculated for each patient. Univariate and multivariate analysis with IBM SPSS Statistics v.26 was used to find the prognostic factors.There was a significant correlation between poor prognosis and older ages, dyspnea, presence of comorbidities, especially cardiovascular and pulmonary. Considering CT features, peripheral and diffuse distribution, anterior and paracardiac involvement, crazy paving pattern, and pleural effusion were correlated with poor prognosis. There was a correlation between total CT-score and prognosis and an 11.5 score was suggested as a cut-off with 67.4 sensitivity and 68.7 specificity in differentiation of poor prognosis patients (patients who needed ICU admission or died. Multivariate analysis revealed that a model consisting of age, male gender, underlying comorbidity, diffused lesions, total CT-score, and dyspnea would predict the",
      "num_citations": 27,
      "url": "https://www.medrxiv.org/content/10.1101/2020.10.30.20223024.abstract",
      "article_id": "prognostic-factors-of-chest-ct-findings--83fbca82",
      "bibtex": "@article{abdollahi2020prognostic,\n    author = {Mohammad Ali Kazemi and Hossein Ghanaati and Behnaz Moradi and Mohammadreza Chavoshi and Hassan Hashemi and Samira Hemmati and Pouria Rouzrokh and Masoumeh Gity and Zahra Ahmadinejad and Hamed Abdollahi},\n    title = {Prognostic factors of chest CT findings for ICU admission and mortality in patients with COVID-19 pneumonia},\n    year = {2020},\n    journal = {MedRxiv},\n    pages = {2020.10. 30.20223024},\n    note = {prognostic-factors-of-chest-ct-findings--83fbca82},\n    url = {https://www.medrxiv.org/content/10.1101/2020.10.30.20223024.abstract},\n    abstract = {Studies have shown that CT could be valuable for prognostic issues in COVID-19to investigate the prognostic factors of early chest CT findings in COVID-19 patients.This retrospective study included 91 patients (34 women, and 57 men) of RT-PCR positive COVID-19 from 3 hospitals in Iran between February 25, 2020, to march 15, 2020. Patients were divided into two groups as good prognosis, discharged from the hospital and alive without symptoms (48 patients), and poor prognosis, died or needed ICU care (43 patients). The first CT images of both groups that were obtained during the first 8 days of the disease presentation were evaluated considering the pattern, distribution, and underlying disease. The total CT-score was calculated for each patient. Univariate and multivariate analysis with IBM SPSS Statistics v.26 was used to find the prognostic factors.There was a significant correlation between poor prognosis and older ages, dyspnea, presence of comorbidities, especially cardiovascular and pulmonary. Considering CT features, peripheral and diffuse distribution, anterior and paracardiac involvement, crazy paving pattern, and pleural effusion were correlated with poor prognosis. There was a correlation between total CT-score and prognosis and an 11.5 score was suggested as a cut-off with 67.4 sensitivity and 68.7 specificity in differentiation of poor prognosis patients (patients who needed ICU admission or died. Multivariate analysis revealed that a model consisting of age, male gender, underlying comorbidity, diffused lesions, total CT-score, and dyspnea would predict the},\n}"
    },
    {
      "title": "Implications of sex difference in CT scan findings and outcome of patients with COVID-19 pneumonia",
      "authors": "Behnaz Moradi, Hossein Ghanaati, Mohammad Ali Kazemi, Masoumeh Gity, Hassan Hashemi, Fateme Davari-Tanha, Mohammadreza Chavoshi, Pouria Rouzrokh, Kasra Kolahdouzan",
      "year": 2020,
      "journal": "Radiology: Cardiothoracic Imaging",
      "volume": "2",
      "number": "4",
      "pages": "e200248",
      "abstract": "The novel coronavirus pandemic has caused significant morbidity and mortality since December 2019. Although the role of chest CT for diagnosing coronavirus disease 2019 (COVID-19) pneumonia is still debatable, the modality has been used in scenarios of constrained reverse-transcription polymerase chain reaction (RT-PCR) testing. The epidemiologic reports indicate an unexplored difference between men and women in disease severity. We aimed to study the role of sex on disease severity and its correlation with CT findings.Authors retrospectively studied all confirmed cases of COVID-19 with thoracic CT scans obtained at three hospitals from February 25, 2020",
      "num_citations": 23,
      "url": "https://pubs.rsna.org/doi/abs/10.1148/ryct.2020200248",
      "article_id": "implications-of-sex-difference-in-ct-sca-df9c8ef8",
      "bibtex": "@article{kolahdouzan2020implications,\n    author = {Behnaz Moradi and Hossein Ghanaati and Mohammad Ali Kazemi and Masoumeh Gity and Hassan Hashemi and Fateme Davari-Tanha and Mohammadreza Chavoshi and Pouria Rouzrokh and Kasra Kolahdouzan},\n    title = {Implications of sex difference in CT scan findings and outcome of patients with COVID-19 pneumonia},\n    year = {2020},\n    journal = {Radiology: Cardiothoracic Imaging},\n    volume = {2},\n    number = {4},\n    pages = {e200248},\n    note = {implications-of-sex-difference-in-ct-sca-df9c8ef8},\n    url = {https://pubs.rsna.org/doi/abs/10.1148/ryct.2020200248},\n    abstract = {The novel coronavirus pandemic has caused significant morbidity and mortality since December 2019. Although the role of chest CT for diagnosing coronavirus disease 2019 (COVID-19) pneumonia is still debatable, the modality has been used in scenarios of constrained reverse-transcription polymerase chain reaction (RT-PCR) testing. The epidemiologic reports indicate an unexplored difference between men and women in disease severity. We aimed to study the role of sex on disease severity and its correlation with CT findings.Authors retrospectively studied all confirmed cases of COVID-19 with thoracic CT scans obtained at three hospitals from February 25, 2020},\n}"
    },
    {
      "title": "Diagnostic value of shear wave sonoelastography in differentiation of benign from malignant thyroid nodules",
      "authors": "Leila Aghaghazvini, Radin Maheronnaghsh, Akbar Soltani, Pouria Rouzrokh, Mohammadreza Chavoshi",
      "year": 2020,
      "journal": "European Journal of Radiology",
      "volume": "126",
      "pages": "108926",
      "abstract": "PurposeTo study the efficacy of shear wave elastography (SWE), using both qualitative and quantitative methods, alone and in conjunction with other B-mode features.Method117 patients with 123 nodules were studied both by conventional ultrasonography and SWE. Size, echogenicity, margins, internal calcification (micro- or macro-calcification), composition, shape and color Doppler were assessed for each nodule. The elasticity was assessed both qualitatively and quantitatively. Velocity in the ROI (Region of Interest) was calculated in the stiffest portions for 3 times, and maximum and mean velocity were obtained. ROC curve was analyzed to calculate the best cut-off value of the SWV (Shear Wave Velocity). Univariate logistic regression was used to examine the maximum and mean SWV as discrete variables and the results were compared to key variables of conventional US (Ultrasound) features.Result123",
      "num_citations": 21,
      "url": "https://www.sciencedirect.com/science/article/pii/S0720048X20301157",
      "article_id": "diagnostic-value-of-shear-wave-sonoelast-664c19c1",
      "bibtex": "@article{chavoshi2020diagnostic,\n    author = {Leila Aghaghazvini and Radin Maheronnaghsh and Akbar Soltani and Pouria Rouzrokh and Mohammadreza Chavoshi},\n    title = {Diagnostic value of shear wave sonoelastography in differentiation of benign from malignant thyroid nodules},\n    year = {2020},\n    journal = {European Journal of Radiology},\n    volume = {126},\n    pages = {108926},\n    note = {diagnostic-value-of-shear-wave-sonoelast-664c19c1},\n    url = {https://www.sciencedirect.com/science/article/pii/S0720048X20301157},\n    abstract = {PurposeTo study the efficacy of shear wave elastography (SWE), using both qualitative and quantitative methods, alone and in conjunction with other B-mode features.Method117 patients with 123 nodules were studied both by conventional ultrasonography and SWE. Size, echogenicity, margins, internal calcification (micro- or macro-calcification), composition, shape and color Doppler were assessed for each nodule. The elasticity was assessed both qualitatively and quantitatively. Velocity in the ROI (Region of Interest) was calculated in the stiffest portions for 3 times, and maximum and mean velocity were obtained. ROC curve was analyzed to calculate the best cut-off value of the SWV (Shear Wave Velocity). Univariate logistic regression was used to examine the maximum and mean SWV as discrete variables and the results were compared to key variables of conventional US (Ultrasound) features.Result123},\n}"
    },
    {
      "title": "Effects of obesity on axillary lymph node structure: association of hilar fat deposition and alterations in cortex width",
      "authors": "Elham Keshavarz, Azadeh Ahangaran, Ensi Khalili Pouya, Radin Maheronnaghsh, Mohammadreza Chavoshi, Pouria Rouzrokh",
      "year": 2020,
      "journal": "Maedica",
      "volume": "15",
      "number": "1",
      "pages": "99",
      "num_citations": 12,
      "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC7221265/",
      "article_id": "effects-of-obesity-on-axillary-lymph-nod-b2b428e9",
      "bibtex": "@article{rouzrokh2020effects,\n    author = {Elham Keshavarz and Azadeh Ahangaran and Ensi Khalili Pouya and Radin Maheronnaghsh and Mohammadreza Chavoshi and Pouria Rouzrokh},\n    title = {Effects of obesity on axillary lymph node structure: association of hilar fat deposition and alterations in cortex width},\n    year = {2020},\n    journal = {Maedica},\n    volume = {15},\n    number = {1},\n    pages = {99},\n    note = {effects-of-obesity-on-axillary-lymph-nod-b2b428e9},\n    url = {https://pmc.ncbi.nlm.nih.gov/articles/PMC7221265/},\n}"
    },
    {
      "title": "U100: an innovative USERN platform for education and research without borders",
      "authors": "Sara Momtazmanesh, Farzaneh Rahmani, Farnaz Delavari, Zahra Vahed, Saleheh Ebadirad, Mahsa KeshavarzFath, L\u00e1szl\u00f3 Rosivall, Hans Ochs, Nima Rezaei",
      "year": 2020,
      "abstract": "Here in the Universal Scientific Education and Research Network (USERN), we relate to the former school, introducing the \"U100\", a collaborative USERN 2 Acta Medica Iranica, Vol. 58, No. 1 (2020) platform for research among at least 100 scientific centers around the glob",
      "num_citations": 3,
      "url": "http://ir.nuozu.edu.ua:8080/bitstream/lib/2601/1/USERN_%D1%81%D1%82%D0%B0%D1%82%D1%82%D1%8F.pdf",
      "article_id": "u100-an-innovative-usern-platform-for-ed-d4d578c1",
      "bibtex": "@article{rezaei2020u100,\n    author = {Sara Momtazmanesh and Farzaneh Rahmani and Farnaz Delavari and Zahra Vahed and Saleheh Ebadirad and Mahsa KeshavarzFath and L\u00e1szl\u00f3 Rosivall and Hans Ochs and Nima Rezaei},\n    title = {U100: an innovative USERN platform for education and research without borders},\n    year = {2020},\n    note = {u100-an-innovative-usern-platform-for-ed-d4d578c1},\n    url = {http://ir.nuozu.edu.ua:8080/bitstream/lib/2601/1/USERN\\_\\%D1\\%81\\%D1\\%82\\%D0\\%B0\\%D1\\%82\\%D1\\%82\\%D1\\%8F.pdf},\n    abstract = {Here in the Universal Scientific Education and Research Network (USERN), we relate to the former school, introducing the \"U100\", a collaborative USERN 2 Acta Medica Iranica, Vol. 58, No. 1 (2020) platform for research among at least 100 scientific centers around the glob},\n}"
    },
    {
      "title": "TOTAL HIP ARTHROPLASTY DISLOCATION RISK USING A MACHINE-LEARNING ALGORITHM",
      "authors": "Cody C Wyles, Hilal Maradit-Kremers, Pouria Rouzrokh, Poulami Barman, Dirk R Larson, Eric C Polley, David G Lewallen, Daniel J Berry, Mark W Pagnano, Michael J Taunton, Robert T Trousdale, Rafael J Sierra",
      "year": 2020,
      "journal": "Orthopaedic Proceedings",
      "volume": "102",
      "number": "SUPP_10",
      "pages": "8-8",
      "abstract": "Instability remains a common complication following total hip arthroplasty (THA) and continues to account for the highest percentage of revisions in numerous registries. Many risk factors have been described, yet a patient-specific risk assessment tool remains elusive. The purpose of this study was to apply a machine learning algorithm to develop a patient-specific risk score capable of dynamic adjustment based on operative decisions.22,086 THA performed between 19982018 were evaluated. 632 THA sustained a postoperative dislocation (2.9). Patients were robustly characterized based on non-modifiable factors: demographics, THA indication, spinal disease, spine surgery, neurologic disease, connective tissue disease; and modifiable operative decisions: surgical approach, femoral head size, acetabular liner (standardelevatedconstraineddual",
      "num_citations": 0,
      "url": "https://boneandjoint.org.uk/article/10.1302/1358-992X.2020.10.008",
      "article_id": "total-hip-arthroplasty-dislocation-risk--f915c007",
      "bibtex": "@article{sierra2020total,\n    author = {Cody C Wyles and Hilal Maradit-Kremers and Pouria Rouzrokh and Poulami Barman and Dirk R Larson and Eric C Polley and David G Lewallen and Daniel J Berry and Mark W Pagnano and Michael J Taunton and Robert T Trousdale and Rafael J Sierra},\n    title = {TOTAL HIP ARTHROPLASTY DISLOCATION RISK USING A MACHINE-LEARNING ALGORITHM},\n    year = {2020},\n    journal = {Orthopaedic Proceedings},\n    volume = {102},\n    number = {SUPP\\_10},\n    pages = {8-8},\n    note = {total-hip-arthroplasty-dislocation-risk--f915c007},\n    url = {https://boneandjoint.org.uk/article/10.1302/1358-992X.2020.10.008},\n    abstract = {Instability remains a common complication following total hip arthroplasty (THA) and continues to account for the highest percentage of revisions in numerous registries. Many risk factors have been described, yet a patient-specific risk assessment tool remains elusive. The purpose of this study was to apply a machine learning algorithm to develop a patient-specific risk score capable of dynamic adjustment based on operative decisions.22,086 THA performed between 19982018 were evaluated. 632 THA sustained a postoperative dislocation (2.9). Patients were robustly characterized based on non-modifiable factors: demographics, THA indication, spinal disease, spine surgery, neurologic disease, connective tissue disease; and modifiable operative decisions: surgical approach, femoral head size, acetabular liner (standardelevatedconstraineddual},\n}"
    },
    {
      "title": "Emerging HIV drug resistance in the resource-poor world: Challenges and strategies.",
      "authors": "K Paydary, S Esmaeeli, SAS Alinaghi, P Rouzrokh, S Emamzadeh-Fard",
      "year": 2013,
      "number": "Suppl. 5",
      "pages": "006",
      "abstract": "At the end of 2011, more than 8 million People Living with HIV (PLWH) were receiving Anti-retroviral Therapy (ART) in low-and middle-income countries 1. Accordingly, the advent and extensive use of Highly Active Anti-retroviral Therapy (HAART) has dramatically reduced the mortality and morbidity associated with the HIV infection worldwide 2. However, many factors such as missing doses of medications, interruptions in ART and mono-therapy in the pre-HAART era may ultimately result in clinical drug resistance and virologic failure 3-8.Many virological, immunological and pharmacological factors may play role in the development of Anti-retroviral Drug Resistance (ADR). First, the rate of viral duplication and turnover associated with HIV infection is too high 4, 9-11. In addition, circulating viral quasispecies may be extremely heterogonous. In fact, the lack of proofreading and an infidel reverse transcriptase can give rise to a genotypically heterogonous horde of circulating viral quasi-species soon after the infection has been established 12, 13. It is noteworthy that developing ADR requires accumulation of genomic changes within host bodily systems 4, 14-18. The consequent genetic diversity may result in the phenotypic drug resistance to various ART agents. Therefore, HIV shows unpredictable patterns of drug resistance in vivo, mainly due to its different adaptation mechanisms to local cellular environments, drugs varying selective pressure, immune system reactions and many other virologic factors 19, 20.",
      "num_citations": 9,
      "url": "https://www.researchgate.net/profile/Shooka-Esmaeeli/publication/286054291_Emerging_HIV_drug_resistance_in_the_Resource-Poor_World_Challenges_and_strategies/links/5c37c2e9299bf12be3be2ebc/Emerging-HIV-drug-resistance-in-the-Resource-Poor-World-Challenges-and-strategies.pdf",
      "article_id": "emerging-hiv-drug-resistance-in-the-reso-85292300",
      "bibtex": "@article{emamzadehfard2013emerging,\n    author = {K Paydary and S Esmaeeli and SAS Alinaghi and P Rouzrokh and S Emamzadeh-Fard},\n    title = {Emerging HIV drug resistance in the resource-poor world: Challenges and strategies.},\n    year = {2013},\n    number = {Suppl. 5},\n    pages = {006},\n    note = {emerging-hiv-drug-resistance-in-the-reso-85292300},\n    url = {https://www.researchgate.net/profile/Shooka-Esmaeeli/publication/286054291\\_Emerging\\_HIV\\_drug\\_resistance\\_in\\_the\\_Resource-Poor\\_World\\_Challenges\\_and\\_strategies/links/5c37c2e9299bf12be3be2ebc/Emerging-HIV-drug-resistance-in-the-Resource-Poor-World-Challenges-and-strategies.pdf},\n    abstract = {At the end of 2011, more than 8 million People Living with HIV (PLWH) were receiving Anti-retroviral Therapy (ART) in low-and middle-income countries 1. Accordingly, the advent and extensive use of Highly Active Anti-retroviral Therapy (HAART) has dramatically reduced the mortality and morbidity associated with the HIV infection worldwide 2. However, many factors such as missing doses of medications, interruptions in ART and mono-therapy in the pre-HAART era may ultimately result in clinical drug resistance and virologic failure 3-8.Many virological, immunological and pharmacological factors may play role in the development of Anti-retroviral Drug Resistance (ADR). First, the rate of viral duplication and turnover associated with HIV infection is too high 4, 9-11. In addition, circulating viral quasispecies may be extremely heterogonous. In fact, the lack of proofreading and an infidel reverse transcriptase can give rise to a genotypically heterogonous horde of circulating viral quasi-species soon after the infection has been established 12, 13. It is noteworthy that developing ADR requires accumulation of genomic changes within host bodily systems 4, 14-18. The consequent genetic diversity may result in the phenotypic drug resistance to various ART agents. Therefore, HIV shows unpredictable patterns of drug resistance in vivo, mainly due to its different adaptation mechanisms to local cellular environments, drugs varying selective pressure, immune system reactions and many other virologic factors 19, 20.},\n}"
    }
  ]
}
